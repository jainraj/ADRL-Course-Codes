{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2f0112",
   "metadata": {},
   "source": [
    "### General Settings\n",
    "\n",
    "Change the respective settings to run appropriately\n",
    "\n",
    "Use `limit_train_batches`, `limit_val_batches`, `limit_test_batches` as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e556aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Users/rajjain/PycharmProjects/ADRL-Course-Work/'\n",
    "data_dir = project_dir + 'data/'\n",
    "bitmoji_data_dir = '/Users/rajjain/Desktop/CourseWork/Bitmoji/'\n",
    "use_gpu = False\n",
    "num_cpus = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3249d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init, Linear, Sequential, Conv2d, PReLU, BatchNorm2d, Flatten, MaxPool2d, InstanceNorm2d\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision import transforms\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "from torch.optim import Adam\n",
    "from torch import autograd\n",
    "import torch\n",
    "import numpy\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f36ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    imgs = torch.stack([elem[0] for elem in batch])\n",
    "    return [imgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f1cd7",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99406d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MALAConstEBM(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "    tau = 0.01\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(MALAConstEBM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0, step_method: str = 'langevin_const'):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            if step_method == 'langevin_const':\n",
    "                xs = self.one_langevin_step(xs, t)\n",
    "            elif step_method == 'langevin_decay':\n",
    "                xs = self.one_langevin_decay_step(xs, t)\n",
    "            elif step_method == 'mala':\n",
    "                xs = self.one_mala_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0, step_method: str = 'langevin_const'):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            if step_method == 'langevin_const':\n",
    "                xs = self.one_langevin_step(xs, t)\n",
    "            elif step_method == 'langevin_decay':\n",
    "                xs = self.one_langevin_decay_step(xs, t)\n",
    "            elif step_method == 'mala':\n",
    "                xs = self.one_mala_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        xs = xs - 0.95 * xs_grad + 0.0005 * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def one_langevin_decay_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        step_size = 1e-4 / (t + 1) ** 0.75\n",
    "        xs = xs - step_size * xs_grad + numpy.sqrt(2 * step_size) * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def one_mala_step(self, xs: torch.Tensor, t):\n",
    "        batch_size = xs.shape[0]\n",
    "\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        proposal_xs = xs - self.tau * xs_grad + numpy.sqrt(2 * self.tau) * torch.randn_like(xs)\n",
    "        proposal_xs.detach_()\n",
    "        proposal_xs.clip_(min=-1, max=1)\n",
    "\n",
    "        proposal_xs.requires_grad_(True)\n",
    "        proposal_xs_output = self.model(proposal_xs)\n",
    "        proposal_xs_grad = autograd.grad(outputs=proposal_xs_output.sum(), inputs=proposal_xs, only_inputs=True)[0]\n",
    "\n",
    "        xs.detach_()\n",
    "        proposal_xs.detach_()\n",
    "        xs_output = xs_output.detach().reshape((-1,))\n",
    "        proposal_xs_output = proposal_xs_output.detach().reshape((-1,))\n",
    "        xs_grad.detach_()\n",
    "        proposal_xs_grad.detach_()\n",
    "\n",
    "        xs_flattened = xs.reshape((batch_size, -1))\n",
    "        proposal_xs_flattened = proposal_xs.reshape((batch_size, -1))\n",
    "        xs_grad_flattened = xs_grad.reshape((batch_size, -1))\n",
    "        proposal_xs_grad_flattened = proposal_xs_grad.reshape((batch_size, -1))\n",
    "\n",
    "        numerator = xs_flattened - proposal_xs_flattened + self.tau * proposal_xs_grad_flattened\n",
    "        numerator = numerator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        denominator = proposal_xs_flattened - xs_flattened + self.tau * xs_grad_flattened\n",
    "        denominator = denominator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        exp_power = -proposal_xs_output + xs_output - numerator / (4 * self.tau) + denominator / (4 * self.tau)\n",
    "        prob = torch.exp(exp_power)\n",
    "\n",
    "        alpha = torch.minimum(prob, torch.ones_like(prob))\n",
    "\n",
    "        u = torch.rand(alpha.shape)\n",
    "\n",
    "        xss = []\n",
    "        for i in range(batch_size):\n",
    "            if u[i] <= alpha[i]:\n",
    "                xss.append(proposal_xs[i])\n",
    "            else:\n",
    "                xss.append(xs[i])\n",
    "\n",
    "        xs = torch.stack(xss)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def mala_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_mala_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        xs, = batch\n",
    "        real_score = self.model(xs).mean()\n",
    "        mala_samples = self.mala_steps(xs.clone())\n",
    "        mala_score = self.model(mala_samples).mean()\n",
    "        loss = real_score - mala_score\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/real_score', real_score, on_step=False, on_epoch=True, logger=True, sync_dist=not_training)\n",
    "        self.log(f'{btype}/fake_score', mala_score, on_step=False, on_epoch=True, logger=True, sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Setting num_workers = 0 as some issue with jupyter and pytorch. in normal implementation, \n",
    "        num_cpus is used. Check GitHub code\"\"\"\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c237f4",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff012a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "Sequential (Sequential)                  [10, 3, 128, 128]         [10, 1]                   --\n",
      "├─Conv2d (0): 1-1                        [10, 3, 128, 128]         [10, 6, 126, 126]         168\n",
      "├─PReLU (1): 1-2                         [10, 6, 126, 126]         [10, 6, 126, 126]         6\n",
      "├─MaxPool2d (2): 1-3                     [10, 6, 126, 126]         [10, 6, 124, 124]         --\n",
      "├─BatchNorm2d (3): 1-4                   [10, 6, 124, 124]         [10, 6, 124, 124]         12\n",
      "├─Conv2d (4): 1-5                        [10, 6, 124, 124]         [10, 6, 122, 122]         330\n",
      "├─PReLU (5): 1-6                         [10, 6, 122, 122]         [10, 6, 122, 122]         6\n",
      "├─MaxPool2d (6): 1-7                     [10, 6, 122, 122]         [10, 6, 120, 120]         --\n",
      "├─BatchNorm2d (7): 1-8                   [10, 6, 120, 120]         [10, 6, 120, 120]         12\n",
      "├─Conv2d (8): 1-9                        [10, 6, 120, 120]         [10, 9, 118, 118]         495\n",
      "├─PReLU (9): 1-10                        [10, 9, 118, 118]         [10, 9, 118, 118]         9\n",
      "├─MaxPool2d (10): 1-11                   [10, 9, 118, 118]         [10, 9, 116, 116]         --\n",
      "├─BatchNorm2d (11): 1-12                 [10, 9, 116, 116]         [10, 9, 116, 116]         18\n",
      "├─Conv2d (12): 1-13                      [10, 9, 116, 116]         [10, 9, 114, 114]         738\n",
      "├─PReLU (13): 1-14                       [10, 9, 114, 114]         [10, 9, 114, 114]         9\n",
      "├─MaxPool2d (14): 1-15                   [10, 9, 114, 114]         [10, 9, 56, 56]           --\n",
      "├─BatchNorm2d (15): 1-16                 [10, 9, 56, 56]           [10, 9, 56, 56]           18\n",
      "├─Conv2d (16): 1-17                      [10, 9, 56, 56]           [10, 9, 54, 54]           738\n",
      "├─PReLU (17): 1-18                       [10, 9, 54, 54]           [10, 9, 54, 54]           9\n",
      "├─MaxPool2d (18): 1-19                   [10, 9, 54, 54]           [10, 9, 26, 26]           --\n",
      "├─BatchNorm2d (19): 1-20                 [10, 9, 26, 26]           [10, 9, 26, 26]           18\n",
      "├─Conv2d (20): 1-21                      [10, 9, 26, 26]           [10, 12, 24, 24]          984\n",
      "├─PReLU (21): 1-22                       [10, 12, 24, 24]          [10, 12, 24, 24]          12\n",
      "├─MaxPool2d (22): 1-23                   [10, 12, 24, 24]          [10, 12, 22, 22]          --\n",
      "├─BatchNorm2d (23): 1-24                 [10, 12, 22, 22]          [10, 12, 22, 22]          24\n",
      "├─Conv2d (24): 1-25                      [10, 12, 22, 22]          [10, 12, 20, 20]          1,308\n",
      "├─PReLU (25): 1-26                       [10, 12, 20, 20]          [10, 12, 20, 20]          12\n",
      "├─MaxPool2d (26): 1-27                   [10, 12, 20, 20]          [10, 12, 18, 18]          --\n",
      "├─BatchNorm2d (27): 1-28                 [10, 12, 18, 18]          [10, 12, 18, 18]          24\n",
      "├─Conv2d (28): 1-29                      [10, 12, 18, 18]          [10, 12, 15, 15]          2,316\n",
      "├─PReLU (29): 1-30                       [10, 12, 15, 15]          [10, 12, 15, 15]          12\n",
      "├─MaxPool2d (30): 1-31                   [10, 12, 15, 15]          [10, 12, 13, 13]          --\n",
      "├─BatchNorm2d (31): 1-32                 [10, 12, 13, 13]          [10, 12, 13, 13]          24\n",
      "├─Conv2d (32): 1-33                      [10, 12, 13, 13]          [10, 15, 10, 10]          2,895\n",
      "├─PReLU (33): 1-34                       [10, 15, 10, 10]          [10, 15, 10, 10]          15\n",
      "├─MaxPool2d (34): 1-35                   [10, 15, 10, 10]          [10, 15, 8, 8]            --\n",
      "├─BatchNorm2d (35): 1-36                 [10, 15, 8, 8]            [10, 15, 8, 8]            30\n",
      "├─Conv2d (36): 1-37                      [10, 15, 8, 8]            [10, 15, 5, 5]            3,615\n",
      "├─PReLU (37): 1-38                       [10, 15, 5, 5]            [10, 15, 5, 5]            15\n",
      "├─MaxPool2d (38): 1-39                   [10, 15, 5, 5]            [10, 15, 3, 3]            --\n",
      "├─BatchNorm2d (39): 1-40                 [10, 15, 3, 3]            [10, 15, 3, 3]            30\n",
      "├─Flatten (40): 1-41                     [10, 15, 3, 3]            [10, 135]                 --\n",
      "├─Linear (41): 1-42                      [10, 135]                 [10, 1]                   136\n",
      "===================================================================================================================\n",
      "Total params: 14,038\n",
      "Trainable params: 14,038\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 282.06\n",
      "===================================================================================================================\n",
      "Input size (MB): 1.97\n",
      "Forward/backward pass size (MB): 102.85\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 104.87\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(MALAConstEBM(bs=1, t=1).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7981790",
   "metadata": {},
   "source": [
    "# Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0d2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(max_epochs: int, tags: list[str], gpu_num: list[int],\n",
    "                   model_class, model_kwargs: dict, model_desc: str,\n",
    "                   limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0):\n",
    "    seed_everything(0, workers=True)\n",
    "\n",
    "    folder_name = datetime.utcnow().isoformat(sep=\"T\", timespec=\"microseconds\")\n",
    "    results_dir = project_dir + f'ebm/results/run_{folder_name}/'\n",
    "    os.makedirs(results_dir, exist_ok=False)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/loss', mode='min', dirpath=results_dir, filename='best',\n",
    "                                          save_last=True)\n",
    "\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "\n",
    "    model = model_class(**model_kwargs)\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs', default_hp_metric=False)\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs, callbacks=[checkpoint_callback],\n",
    "                      logger=[tf_logger], log_every_n_steps=1, num_sanity_val_steps=0, deterministic=True,\n",
    "                      limit_train_batches=limit_train_batches, limit_val_batches=limit_val_batches,\n",
    "                      limit_test_batches=limit_test_batches,\n",
    "                      **trainer_kwargs)\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model, ckpt_path='best')\n",
    "\n",
    "    summary = model.summary() + '\\n' + model_desc\n",
    "    with open(results_dir + 'model_desc.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f8a5d",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61266d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 14.0 K\n",
      "-------------------------------------\n",
      "14.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.0 K    Total params\n",
      "0.056     Total estimated model params size (MB)\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012258052825927734,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6af5d90a80f4f2e902aec110e7e1b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007311105728149414,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007368803024291992,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/ebm/results/run_2022-11-09T14:05:28.298565/best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/ebm/results/run_2022-11-09T14:05:28.298565/best.ckpt\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007601022720336914,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7b67a1fa724b9bb8f3bf3890d2a4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/fake_score        -1.0585254430770874\n",
      "        test/loss           0.10533779859542847\n",
      "     test/real_score        -0.9531876444816589\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# bs is batch_size \n",
    "train_and_test(max_epochs=2, tags=[], gpu_num=[], model_class=MALAConstEBM,\n",
    "               model_kwargs=dict(bs=10, t=1), model_desc='EBM Model with MALA with constant step size', \n",
    "               limit_train_batches=2, limit_val_batches=2, limit_test_batches=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa3542",
   "metadata": {},
   "source": [
    "# Plots & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3c2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side(title, samples, fname, size):\n",
    "    fig, axes = plt.subplots(size, size, figsize=(8, 8))\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01, left=0, bottom=0, right=1, top=0.95)\n",
    "    axes = axes.flat\n",
    "\n",
    "    for i in range(samples.shape[0]):\n",
    "        ax = axes[i]\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(samples[i])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.savefig(project_dir + f'ebm/img_results/{fname}.png')\n",
    "\n",
    "\n",
    "def convert_to_image(ndarray):\n",
    "    # ndarray = numpy.clip(ndarray, -1, 1)  # -1 to 1\n",
    "    ndarray = ndarray * 0.5 + 0.5  # 0 to 1\n",
    "    ndarray *= 255  # 0 to 255\n",
    "    ndarray = numpy.round(ndarray, decimals=0)  # rounded off\n",
    "    return ndarray.astype(int)\n",
    "\n",
    "\n",
    "def see_some_generations(model, model_type, step_method):\n",
    "    samples = model.gen_samples(num_samples=100, steps=100, step_method=step_method)\n",
    "    samples = convert_to_image(numpy.transpose(samples.detach().numpy(), (0, 2, 3, 1)))\n",
    "    plot_side_by_side(f'{model.__class__.__name__} EBM Bitmoji - t = {model.t} - {model_type} - {step_method}', samples,\n",
    "                      f'{model.__class__.__name__}_ebm_gen_t={model.t}_{model_type}_{step_method}', size=10)\n",
    "\n",
    "\n",
    "def see_some_transitions(model, model_type, jump, step_method):\n",
    "    samples = model.get_transition(steps=225, jump=jump, seed=0, step_method=step_method)\n",
    "    samples = convert_to_image(numpy.transpose(samples.detach().numpy(), (0, 2, 3, 1)))\n",
    "    plot_side_by_side(f'{model.__class__.__name__} Bitmoji Transitions - t = {model.t}, jump = {jump} - {model_type} - {step_method}', samples,\n",
    "                      f'{model.__class__.__name__}_ebm_trans_t={model.t}_jump={jump}_{model_type}_{step_method}', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c9ee1",
   "metadata": {},
   "source": [
    "# Other Models Tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangConstEBM(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(LangConstEBM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        xs = xs - 0.95 * xs_grad + 0.0005 * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def langevin_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        xs, = batch\n",
    "        real_score = self.model(xs).mean()\n",
    "        langevin_samples = self.langevin_steps(xs.clone())\n",
    "        langevin_score = self.model(langevin_samples).mean()\n",
    "        loss = real_score - langevin_score\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
    "                 sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n",
    "\n",
    "\n",
    "class LangDecayEBM(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(LangDecayEBM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        step_size = 1e-4 / (t + 1) ** 0.75\n",
    "        xs = xs - step_size * xs_grad + numpy.sqrt(2 * step_size) * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def langevin_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        xs, = batch\n",
    "        real_score = self.model(xs).mean()\n",
    "        langevin_samples = self.langevin_steps(xs.clone())\n",
    "        langevin_score = self.model(langevin_samples).mean()\n",
    "        loss = real_score - langevin_score\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
    "                 sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n",
    "\n",
    "\n",
    "class LangConstEBMReg(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(LangConstEBMReg, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        xs = xs - 0.95 * xs_grad + 0.0005 * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def langevin_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        xs, = batch\n",
    "        real_score = self.model(xs).mean()\n",
    "        langevin_samples = self.langevin_steps(xs.clone())\n",
    "        langevin_score = self.model(langevin_samples).mean()\n",
    "        loss = real_score - langevin_score\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
    "                 sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n",
    "\n",
    "\n",
    "class MALAConstOPRegEBM(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "    tau = 0.01\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(MALAConstOPRegEBM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        xs = xs - 0.95 * xs_grad + 0.0005 * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def one_mala_step(self, xs: torch.Tensor, t):\n",
    "        batch_size = xs.shape[0]\n",
    "\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        proposal_xs = xs - self.tau * xs_grad + numpy.sqrt(2 * self.tau) * torch.randn_like(xs)\n",
    "        proposal_xs.detach_()\n",
    "        proposal_xs.clip_(min=-1, max=1)\n",
    "\n",
    "        proposal_xs.requires_grad_(True)\n",
    "        proposal_xs_output = self.model(proposal_xs)\n",
    "        proposal_xs_grad = autograd.grad(outputs=proposal_xs_output.sum(), inputs=proposal_xs, only_inputs=True)[0]\n",
    "\n",
    "        xs.detach_()\n",
    "        proposal_xs.detach_()\n",
    "        xs_output = xs_output.detach().reshape((-1,))\n",
    "        proposal_xs_output = proposal_xs_output.detach().reshape((-1,))\n",
    "        xs_grad.detach_()\n",
    "        proposal_xs_grad.detach_()\n",
    "\n",
    "        xs_flattened = xs.reshape((batch_size, -1))\n",
    "        proposal_xs_flattened = proposal_xs.reshape((batch_size, -1))\n",
    "        xs_grad_flattened = xs_grad.reshape((batch_size, -1))\n",
    "        proposal_xs_grad_flattened = proposal_xs_grad.reshape((batch_size, -1))\n",
    "\n",
    "        numerator = xs_flattened - proposal_xs_flattened + self.tau * proposal_xs_grad_flattened\n",
    "        numerator = numerator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        denominator = proposal_xs_flattened - xs_flattened + self.tau * xs_grad_flattened\n",
    "        denominator = denominator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        exp_power = -proposal_xs_output + xs_output - numerator / (4 * self.tau) + denominator / (4 * self.tau)\n",
    "        prob = torch.exp(exp_power)\n",
    "\n",
    "        alpha = torch.minimum(prob, torch.ones_like(prob))\n",
    "\n",
    "        u = torch.rand(alpha.shape)\n",
    "\n",
    "        xss = []\n",
    "        for i in range(batch_size):\n",
    "            if u[i] <= alpha[i]:\n",
    "                xss.append(proposal_xs[i])\n",
    "            else:\n",
    "                xss.append(xs[i])\n",
    "\n",
    "        xs = torch.stack(xss)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def mala_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_mala_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        xs, = batch\n",
    "\n",
    "        real_outputs = self.model(xs)\n",
    "        mala_samples = self.mala_steps(xs.clone())\n",
    "        mala_outputs = self.model(mala_samples)\n",
    "\n",
    "        reg_loss = 0.1 * (real_outputs ** 2 + mala_outputs ** 2).mean()\n",
    "\n",
    "        real_score = real_outputs.mean()\n",
    "        mala_score = mala_outputs.mean()\n",
    "        div_loss = real_score - mala_score\n",
    "        loss = div_loss + reg_loss\n",
    "\n",
    "        self.log(f'train/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, sync_dist=False)\n",
    "        self.log(f'train/real_score', real_score, on_step=False, on_epoch=True, logger=True, sync_dist=False)\n",
    "        self.log(f'train/fake_score', mala_score, on_step=False, on_epoch=True, logger=True, sync_dist=False)\n",
    "        self.log(f'train/div_loss', div_loss, on_step=False, on_epoch=True, logger=True, sync_dist=False)\n",
    "        self.log(f'train/reg_loss', reg_loss, on_step=False, on_epoch=True, logger=True, sync_dist=False)\n",
    "        return loss\n",
    "\n",
    "    def _common_eval_step(self, batch, btype):\n",
    "        xs, = batch\n",
    "        fakes = 2 * torch.rand_like(xs) - 1\n",
    "\n",
    "        real_score = self.model(xs).mean()\n",
    "        fake_score = self.model(fakes).mean()\n",
    "        div_loss = real_score - fake_score\n",
    "        loss = torch.abs(div_loss)\n",
    "\n",
    "        self.log(f'{btype}/real_score', real_score, on_step=False, on_epoch=True, logger=True, sync_dist=True)\n",
    "        self.log(f'{btype}/fake_score', fake_score, on_step=False, on_epoch=True, logger=True, sync_dist=True)\n",
    "        self.log(f'{btype}/div_loss', div_loss, on_step=False, on_epoch=True, logger=True, sync_dist=True)\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, logger=True, sync_dist=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._common_eval_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._common_eval_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n",
    "\n",
    "\n",
    "class MALAConstInstanceEBM(LightningModule):\n",
    "    \"\"\"\n",
    "    EBM for Bitmoji images.\n",
    "    We assume a form p_theta(x) = exp(-E_theta(x)) / z_theta\n",
    "    \"\"\"\n",
    "    tau = 0.01\n",
    "\n",
    "    def __init__(self, bs, t):\n",
    "        super(MALAConstInstanceEBM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bs = bs\n",
    "        self.t = t\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=6, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=6, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=9, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            InstanceNorm2d(num_features=9, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            InstanceNorm2d(num_features=9, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=12, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=12, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=12, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=15, affine=True),\n",
    "\n",
    "            Conv2d(in_channels=15, out_channels=15, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(1, 1)),\n",
    "            InstanceNorm2d(num_features=15, affine=True),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=135, out_features=1),\n",
    "        )\n",
    "\n",
    "        self.initialise()\n",
    "        self.float()\n",
    "\n",
    "    def initialise(self):\n",
    "        seed_everything(0)\n",
    "        for i in range(0, 37, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['41'].weight)\n",
    "\n",
    "    def gen_samples(self, num_samples, steps=100, seed=0):\n",
    "        seed_everything(seed)\n",
    "        xs = 2 * torch.rand((num_samples, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def get_transition(self, steps=100, jump=1, seed=0):\n",
    "        seed_everything(seed)\n",
    "        transitions = []\n",
    "        xs = 2 * torch.rand((1, 3, 128, 128), dtype=torch.float) - 1\n",
    "        for t in range(steps * jump):\n",
    "            xs = self.one_langevin_step(xs, t)\n",
    "            if t % jump == 0:\n",
    "                transitions.append(xs[0])\n",
    "        return torch.stack(transitions)\n",
    "\n",
    "    def one_langevin_step(self, xs: torch.Tensor, t):\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        xs = xs - 0.95 * xs_grad + 0.0005 * torch.randn_like(xs)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def one_mala_step(self, xs: torch.Tensor, t):\n",
    "        batch_size = xs.shape[0]\n",
    "\n",
    "        xs.requires_grad_(True)\n",
    "        xs_output = self.model(xs)\n",
    "        xs_grad = autograd.grad(outputs=xs_output.sum(), inputs=xs, only_inputs=True)[0]\n",
    "        proposal_xs = xs - self.tau * xs_grad + numpy.sqrt(2 * self.tau) * torch.randn_like(xs)\n",
    "        proposal_xs.detach_()\n",
    "        proposal_xs.clip_(min=-1, max=1)\n",
    "\n",
    "        proposal_xs.requires_grad_(True)\n",
    "        proposal_xs_output = self.model(proposal_xs)\n",
    "        proposal_xs_grad = autograd.grad(outputs=proposal_xs_output.sum(), inputs=proposal_xs, only_inputs=True)[0]\n",
    "\n",
    "        xs.detach_()\n",
    "        proposal_xs.detach_()\n",
    "        xs_output = xs_output.detach().reshape((-1,))\n",
    "        proposal_xs_output = proposal_xs_output.detach().reshape((-1,))\n",
    "        xs_grad.detach_()\n",
    "        proposal_xs_grad.detach_()\n",
    "\n",
    "        xs_flattened = xs.reshape((batch_size, -1))\n",
    "        proposal_xs_flattened = proposal_xs.reshape((batch_size, -1))\n",
    "        xs_grad_flattened = xs_grad.reshape((batch_size, -1))\n",
    "        proposal_xs_grad_flattened = proposal_xs_grad.reshape((batch_size, -1))\n",
    "\n",
    "        numerator = xs_flattened - proposal_xs_flattened + self.tau * proposal_xs_grad_flattened\n",
    "        numerator = numerator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        denominator = proposal_xs_flattened - xs_flattened + self.tau * xs_grad_flattened\n",
    "        denominator = denominator.norm(p=2, dim=1) ** 2\n",
    "\n",
    "        exp_power = -proposal_xs_output + xs_output - numerator / (4 * self.tau) + denominator / (4 * self.tau)\n",
    "        prob = torch.exp(exp_power)\n",
    "\n",
    "        alpha = torch.minimum(prob, torch.ones_like(prob))\n",
    "\n",
    "        u = torch.rand(alpha.shape)\n",
    "\n",
    "        xss = []\n",
    "        for i in range(batch_size):\n",
    "            if u[i] <= alpha[i]:\n",
    "                xss.append(proposal_xs[i])\n",
    "            else:\n",
    "                xss.append(xs[i])\n",
    "\n",
    "        xs = torch.stack(xss)\n",
    "        xs.detach_()\n",
    "        xs.clip_(min=-1, max=1)\n",
    "        return xs\n",
    "\n",
    "    def mala_steps(self, xs: torch.Tensor):\n",
    "        for t in range(self.t):\n",
    "            xs = self.one_mala_step(xs, t)\n",
    "        return xs.clone()\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        xs, = batch\n",
    "        real_score = self.model(xs).mean()\n",
    "        mala_samples = self.mala_steps(xs.clone())\n",
    "        mala_score = self.model(mala_samples).mean()\n",
    "        loss = real_score - mala_score\n",
    "        self.log(f'{btype}/loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True,\n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/real_score', real_score, on_step=False, on_epoch=True, logger=True, sync_dist=not_training)\n",
    "        self.log(f'{btype}/fake_score', mala_score, on_step=False, on_epoch=True, logger=True, sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._common_step(batch, 'train')\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return bitmoji_dataloader\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        _summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                               row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        _bitmoji = torch.randn((10, 3, 128, 128), dtype=torch.float)\n",
    "        _summary_string = str(summary(model=self.model, input_data=_bitmoji, **_summary_kwargs))\n",
    "        return _summary_string\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
