{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08be90d1",
   "metadata": {},
   "source": [
    "### General Settings\n",
    "\n",
    "Change the respective settings to run appropriately\n",
    "\n",
    "Use `limit_train_batches`, `limit_val_batches`, `limit_test_batches` as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582ec6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Users/rajjain/PycharmProjects/ADRL-Course-Work/'\n",
    "data_dir = project_dir + 'data/'\n",
    "mnist_data_dir = '/Users/rajjain/Desktop/CourseWork/MNIST/'\n",
    "usps_data_dir = '/Users/rajjain/Desktop/CourseWork/USPS/'\n",
    "clipart_data_dir = '/Users/rajjain/Desktop/CourseWork/Clipart/'\n",
    "realworld_data_dir = '/Users/rajjain/Desktop/CourseWork/RealWorld/'\n",
    "use_gpu = False\n",
    "num_cpus = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc6134",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf92cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, Flatten, Module, init, CrossEntropyLoss, ReLU\n",
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchvision.datasets import USPS, MNIST\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision import transforms\n",
    "from torch.optim import Adam\n",
    "from torchinfo import summary\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import torch\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74463738",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a214792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Repeater:\n",
    "    def __call__(self, gray: torch.Tensor):\n",
    "        return torch.concat([gray, gray, gray])\n",
    "\n",
    "\n",
    "def get_dataset(dataset: str, train: bool):\n",
    "    if dataset == 'mnist':\n",
    "        mnist_dataset = MNIST(mnist_data_dir, train=train,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.Resize(28),\n",
    "                                  transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                  Repeater(),\n",
    "                                  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                              ]))\n",
    "        return mnist_dataset\n",
    "    if dataset == 'usps':\n",
    "        usps_dataset = USPS(usps_data_dir, train=train,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(22),\n",
    "                                transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                Repeater(),\n",
    "                                transforms.Pad(padding=3, fill=0),\n",
    "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                            ]))\n",
    "        return usps_dataset\n",
    "    if dataset == 'clipart':\n",
    "        clipart_dataset = ImageFolder(clipart_data_dir + ('train/' if train else 'test/'),\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.Resize((256, 256)),  # Squish / Extrapolate to 256 X 256\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                                      ]))\n",
    "        return clipart_dataset\n",
    "    if dataset == 'realworld':\n",
    "        realworld_dataset = ImageFolder(realworld_data_dir + ('train/' if train else 'test/'),\n",
    "                                        transform=transforms.Compose([\n",
    "                                            transforms.Resize((256, 256)),  # Squish / Extrapolate to 256 X 256\n",
    "                                            transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                                        ]))\n",
    "        return realworld_dataset\n",
    "\n",
    "    \n",
    "def split_results(pred_results):\n",
    "    targets, preds = [], []\n",
    "    for t, p in pred_results:\n",
    "        targets.append(t)\n",
    "        preds.append(p)\n",
    "    target = torch.concat(targets)\n",
    "    pred = torch.concat(preds)\n",
    "    return target, pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42ddb32",
   "metadata": {},
   "source": [
    "# MNIST-USPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1941630c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ea74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(Module):\n",
    "    \"\"\"Resnet based feature extractor\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        backbone = resnet50(pretrained=True)\n",
    "        layers = list(backbone.children())[:-1]  # Until AdaptiveAvgPool2d Layer\n",
    "        self.model = Sequential(\n",
    "            *layers,\n",
    "            Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: batch of images\n",
    "        :return: batch of 2048 dim vectors\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Classifier(Module):\n",
    "    \"\"\"A simple classifier\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = Sequential(\n",
    "            Linear(in_features=2048, out_features=32),\n",
    "            ReLU(),\n",
    "            Linear(in_features=32, out_features=num_classes),  # Output Logits\n",
    "        )\n",
    "        seed_everything(0)\n",
    "        init.kaiming_normal_(self.model[0].weight, nonlinearity='relu')\n",
    "        init.xavier_uniform_(self.model[2].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class SourceClassifier(LightningModule):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(SourceClassifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.classifier = Classifier(num_classes)\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = CrossEntropyLoss()(y_hat, y)\n",
    "        acc = accuracy(y_hat, y, average='macro', num_classes=self.num_classes, multiclass=True)\n",
    "        self.log(f'{btype}/source_loss', loss, on_step=False, on_epoch=True, sync_dist=not_training)\n",
    "        self.log(f'{btype}/source_acc', acc, on_step=False, on_epoch=True, sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=3, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                              row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        source_imgs = torch.randn((10, 3, 28, 28), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self, input_data=source_imgs, **summary_kwargs))\n",
    "        return summary_string\n",
    "\n",
    "\n",
    "class AdversarialAdapter(LightningModule):\n",
    "\n",
    "    def __init__(self, source_feature_extractor: FeatureExtractor, ncritic, ngen, penalty_weight):\n",
    "        \"\"\"\n",
    "        :param source_feature_extractor: trained source feature extractor. its weights will not be updated here.\n",
    "        \"\"\"\n",
    "        super(AdversarialAdapter, self).__init__()\n",
    "        self.save_hyperparameters(ignore=['source_feature_extractor'])\n",
    "        self.ncritic = ncritic\n",
    "        self.ngen = ngen\n",
    "        self.penalty_weight = penalty_weight\n",
    "\n",
    "        self.source_feature_extractor = FeatureExtractor()  # this works as the real samples\n",
    "        self.source_feature_extractor.load_state_dict(source_feature_extractor.state_dict())\n",
    "        self.source_feature_extractor.requires_grad_(False)\n",
    "        self.target_feature_extractor = FeatureExtractor()  # this works as the generator - which needs to be trained\n",
    "        self.target_feature_extractor.load_state_dict(source_feature_extractor.state_dict())\n",
    "\n",
    "        self.critic = Sequential(\n",
    "            Linear(in_features=2048, out_features=32),\n",
    "            ReLU(),\n",
    "            Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "        seed_everything(0)\n",
    "        init.kaiming_normal_(self.critic[0].weight, nonlinearity='relu')\n",
    "        init.xavier_uniform_(self.critic[2].weight)\n",
    "        self.float()\n",
    "\n",
    "    def _gradient_penalty(self, batch):\n",
    "        source_imgs, target_imgs = batch['source'][0], batch['target'][0]\n",
    "        batch_size = source_imgs.shape[0]\n",
    "        source_features = self.source_feature_extractor(source_imgs)\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        eps = torch.rand(batch_size, 1, device=self.device)\n",
    "        eps = eps.expand_as(source_features)\n",
    "        interpolated = eps * source_features + (1 - eps) * target_features\n",
    "        interpolated.requires_grad_(True)\n",
    "        interpolated_scores = self.critic(interpolated)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=interpolated_scores,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(interpolated_scores),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradients_norm = gradients.norm(2, 1)  # norm of gradient each of the samples\n",
    "        penalty = (gradients_norm - 1) ** 2  # penalty for each sample\n",
    "        gp = self.penalty_weight * penalty.mean()  # mean across samples\n",
    "        return gp\n",
    "\n",
    "    def _critic_loss(self, batch):\n",
    "        source_imgs, target_imgs = batch['source'][0], batch['target'][0]\n",
    "        source_features = self.source_feature_extractor(source_imgs)\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        source_score = self.critic(source_features).mean()  # \"real\"\n",
    "        target_score = self.critic(target_features).mean()  # \"fake\"\n",
    "        critic_loss = target_score - source_score  # \"fake\" - \"real\"\n",
    "        return critic_loss, source_score, target_score\n",
    "\n",
    "    def _gen_loss(self, batch):\n",
    "        target_imgs = batch['target'][0]\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        target_score = self.critic(target_features).mean()\n",
    "        gen_loss = -target_score\n",
    "        return gen_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        self.source_feature_extractor.eval()\n",
    "        if optimizer_idx == 1:  # Critic optimizer - only update Critic weights\n",
    "            critic_loss, source_score, target_score = self._critic_loss(batch)\n",
    "            gp = self._gradient_penalty(batch)\n",
    "            self.log(f'train/critic_loss', critic_loss, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/gp', gp, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/source_score', source_score, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/target_score', target_score, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            return critic_loss + gp\n",
    "\n",
    "        if optimizer_idx == 0:  # Generator optimizer - only update Generator weights\n",
    "            gen_loss = self._gen_loss(batch)\n",
    "            self.log(f'train/gen_loss', gen_loss, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            return gen_loss\n",
    "\n",
    "        raise Exception(f'Unknown optimizer index: {optimizer_idx}')\n",
    "\n",
    "    def _shared_eval(self, batch, btype):\n",
    "        critic_loss, source_score, target_score = self._critic_loss(batch)\n",
    "        emd = torch.abs(critic_loss)\n",
    "        actual_emd = -critic_loss\n",
    "        self.log(f'{btype}/actual_emd', actual_emd, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/emd', emd, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/critic_loss', critic_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/source_score', source_score, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/target_score', target_score, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        gp = self._gradient_penalty(batch)\n",
    "        gen_loss = self._gen_loss(batch)\n",
    "        self.log(f'{btype}/gp', gp, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/gen_loss', gen_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._shared_eval(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._shared_eval(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        generator_opt = Adam(params=self.target_feature_extractor.parameters(), lr=0.0001, betas=(0, 0.9))\n",
    "        critic_opt = Adam(params=self.critic.parameters(), lr=0.0001, betas=(0, 0.9))\n",
    "        return (\n",
    "            {\"optimizer\": generator_opt, \"frequency\": self.ngen},\n",
    "            {\"optimizer\": critic_opt, \"frequency\": self.ncritic},\n",
    "        )\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=3, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                             row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        source_imgs = torch.randn((10, 3, 28, 28), dtype=torch.float)\n",
    "        target_imgs = torch.randn((10, 3, 28, 28), dtype=torch.float)\n",
    "        features = torch.randn((10, 2048), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self.source_feature_extractor, input_data=source_imgs, **summary_kwargs)) + '\\n' + \\\n",
    "                         str(summary(model=self.target_feature_extractor, input_data=target_imgs, **summary_kwargs)) + '\\n' + \\\n",
    "                         str(summary(model=self.critic, input_data=features, **summary_kwargs))\n",
    "        return summary_string\n",
    "\n",
    "    \n",
    "class TargetClassifier(LightningModule):\n",
    "    \"\"\"For the sake of completion\"\"\"\n",
    "\n",
    "    def __init__(self, target_feature_extractor: FeatureExtractor, classifier: Classifier):\n",
    "        super(TargetClassifier, self).__init__()\n",
    "        self.save_hyperparameters(ignore=['target_feature_extractor', 'classifier'])\n",
    "        self.target_feature_extractor = target_feature_extractor\n",
    "        self.classifier = classifier\n",
    "        self.target_feature_extractor.requires_grad_(False)\n",
    "        self.classifier.requires_grad_(False)\n",
    "\n",
    "    def forward(self, target_imgs):\n",
    "        features = self.target_feature_extractor(target_imgs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return y.detach(), y_hat.detach()\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=3, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                              row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        target_imgs = torch.randn((10, 3, 28, 28), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self, input_data=target_imgs, **summary_kwargs))\n",
    "        return summary_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6633ca67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #\n",
      "=======================================================================================================================================\n",
      "SourceClassifier (SourceClassifier)                          [10, 3, 28, 28]           [10, 10]                  --\n",
      "├─FeatureExtractor (feature_extractor): 1-1                  [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    └─Sequential (model): 2-1                               [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    │    └─Conv2d (0): 3-1                                  [10, 3, 28, 28]           [10, 64, 14, 14]          9,408\n",
      "│    │    └─BatchNorm2d (1): 3-2                             [10, 64, 14, 14]          [10, 64, 14, 14]          128\n",
      "│    │    └─ReLU (2): 3-3                                    [10, 64, 14, 14]          [10, 64, 14, 14]          --\n",
      "│    │    └─MaxPool2d (3): 3-4                               [10, 64, 14, 14]          [10, 64, 7, 7]            --\n",
      "│    │    └─Sequential (4): 3-5                              [10, 64, 7, 7]            [10, 256, 7, 7]           215,808\n",
      "│    │    └─Sequential (5): 3-6                              [10, 256, 7, 7]           [10, 512, 4, 4]           1,219,584\n",
      "│    │    └─Sequential (6): 3-7                              [10, 512, 4, 4]           [10, 1024, 2, 2]          7,098,368\n",
      "│    │    └─Sequential (7): 3-8                              [10, 1024, 2, 2]          [10, 2048, 1, 1]          14,964,736\n",
      "│    │    └─AdaptiveAvgPool2d (8): 3-9                       [10, 2048, 1, 1]          [10, 2048, 1, 1]          --\n",
      "│    │    └─Flatten (9): 3-10                                [10, 2048, 1, 1]          [10, 2048]                --\n",
      "├─Classifier (classifier): 1-2                               [10, 2048]                [10, 10]                  --\n",
      "│    └─Sequential (model): 2-2                               [10, 2048]                [10, 10]                  --\n",
      "│    │    └─Linear (0): 3-11                                 [10, 2048]                [10, 32]                  65,568\n",
      "│    │    └─ReLU (1): 3-12                                   [10, 32]                  [10, 32]                  --\n",
      "│    │    └─Linear (2): 3-13                                 [10, 32]                  [10, 10]                  330\n",
      "=======================================================================================================================================\n",
      "Total params: 23,573,930\n",
      "Trainable params: 23,573,930\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 792.79\n",
      "=======================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 31.99\n",
      "Params size (MB): 94.30\n",
      "Estimated Total Size (MB): 126.38\n",
      "=======================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #\n",
      "==================================================================================================================================\n",
      "FeatureExtractor (FeatureExtractor)                     [10, 3, 28, 28]           [10, 2048]                --\n",
      "├─Sequential (model): 1-1                               [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    └─Conv2d (0): 2-1                                  [10, 3, 28, 28]           [10, 64, 14, 14]          (9,408)\n",
      "│    └─BatchNorm2d (1): 2-2                             [10, 64, 14, 14]          [10, 64, 14, 14]          (128)\n",
      "│    └─ReLU (2): 2-3                                    [10, 64, 14, 14]          [10, 64, 14, 14]          --\n",
      "│    └─MaxPool2d (3): 2-4                               [10, 64, 14, 14]          [10, 64, 7, 7]            --\n",
      "│    └─Sequential (4): 2-5                              [10, 64, 7, 7]            [10, 256, 7, 7]           --\n",
      "│    │    └─Bottleneck (0): 3-1                         [10, 64, 7, 7]            [10, 256, 7, 7]           (75,008)\n",
      "│    │    └─Bottleneck (1): 3-2                         [10, 256, 7, 7]           [10, 256, 7, 7]           (70,400)\n",
      "│    │    └─Bottleneck (2): 3-3                         [10, 256, 7, 7]           [10, 256, 7, 7]           (70,400)\n",
      "│    └─Sequential (5): 2-6                              [10, 256, 7, 7]           [10, 512, 4, 4]           --\n",
      "│    │    └─Bottleneck (0): 3-4                         [10, 256, 7, 7]           [10, 512, 4, 4]           (379,392)\n",
      "│    │    └─Bottleneck (1): 3-5                         [10, 512, 4, 4]           [10, 512, 4, 4]           (280,064)\n",
      "│    │    └─Bottleneck (2): 3-6                         [10, 512, 4, 4]           [10, 512, 4, 4]           (280,064)\n",
      "│    │    └─Bottleneck (3): 3-7                         [10, 512, 4, 4]           [10, 512, 4, 4]           (280,064)\n",
      "│    └─Sequential (6): 2-7                              [10, 512, 4, 4]           [10, 1024, 2, 2]          --\n",
      "│    │    └─Bottleneck (0): 3-8                         [10, 512, 4, 4]           [10, 1024, 2, 2]          (1,512,448)\n",
      "│    │    └─Bottleneck (1): 3-9                         [10, 1024, 2, 2]          [10, 1024, 2, 2]          (1,117,184)\n",
      "│    │    └─Bottleneck (2): 3-10                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          (1,117,184)\n",
      "│    │    └─Bottleneck (3): 3-11                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          (1,117,184)\n",
      "│    │    └─Bottleneck (4): 3-12                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          (1,117,184)\n",
      "│    │    └─Bottleneck (5): 3-13                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          (1,117,184)\n",
      "│    └─Sequential (7): 2-8                              [10, 1024, 2, 2]          [10, 2048, 1, 1]          --\n",
      "│    │    └─Bottleneck (0): 3-14                        [10, 1024, 2, 2]          [10, 2048, 1, 1]          (6,039,552)\n",
      "│    │    └─Bottleneck (1): 3-15                        [10, 2048, 1, 1]          [10, 2048, 1, 1]          (4,462,592)\n",
      "│    │    └─Bottleneck (2): 3-16                        [10, 2048, 1, 1]          [10, 2048, 1, 1]          (4,462,592)\n",
      "│    └─AdaptiveAvgPool2d (8): 2-9                       [10, 2048, 1, 1]          [10, 2048, 1, 1]          --\n",
      "│    └─Flatten (9): 2-10                                [10, 2048, 1, 1]          [10, 2048]                --\n",
      "==================================================================================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,508,032\n",
      "Total mult-adds (M): 792.13\n",
      "==================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 31.99\n",
      "Params size (MB): 94.03\n",
      "Estimated Total Size (MB): 126.12\n",
      "==================================================================================================================================\n",
      "==================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #\n",
      "==================================================================================================================================\n",
      "FeatureExtractor (FeatureExtractor)                     [10, 3, 28, 28]           [10, 2048]                --\n",
      "├─Sequential (model): 1-1                               [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    └─Conv2d (0): 2-1                                  [10, 3, 28, 28]           [10, 64, 14, 14]          9,408\n",
      "│    └─BatchNorm2d (1): 2-2                             [10, 64, 14, 14]          [10, 64, 14, 14]          128\n",
      "│    └─ReLU (2): 2-3                                    [10, 64, 14, 14]          [10, 64, 14, 14]          --\n",
      "│    └─MaxPool2d (3): 2-4                               [10, 64, 14, 14]          [10, 64, 7, 7]            --\n",
      "│    └─Sequential (4): 2-5                              [10, 64, 7, 7]            [10, 256, 7, 7]           --\n",
      "│    │    └─Bottleneck (0): 3-1                         [10, 64, 7, 7]            [10, 256, 7, 7]           75,008\n",
      "│    │    └─Bottleneck (1): 3-2                         [10, 256, 7, 7]           [10, 256, 7, 7]           70,400\n",
      "│    │    └─Bottleneck (2): 3-3                         [10, 256, 7, 7]           [10, 256, 7, 7]           70,400\n",
      "│    └─Sequential (5): 2-6                              [10, 256, 7, 7]           [10, 512, 4, 4]           --\n",
      "│    │    └─Bottleneck (0): 3-4                         [10, 256, 7, 7]           [10, 512, 4, 4]           379,392\n",
      "│    │    └─Bottleneck (1): 3-5                         [10, 512, 4, 4]           [10, 512, 4, 4]           280,064\n",
      "│    │    └─Bottleneck (2): 3-6                         [10, 512, 4, 4]           [10, 512, 4, 4]           280,064\n",
      "│    │    └─Bottleneck (3): 3-7                         [10, 512, 4, 4]           [10, 512, 4, 4]           280,064\n",
      "│    └─Sequential (6): 2-7                              [10, 512, 4, 4]           [10, 1024, 2, 2]          --\n",
      "│    │    └─Bottleneck (0): 3-8                         [10, 512, 4, 4]           [10, 1024, 2, 2]          1,512,448\n",
      "│    │    └─Bottleneck (1): 3-9                         [10, 1024, 2, 2]          [10, 1024, 2, 2]          1,117,184\n",
      "│    │    └─Bottleneck (2): 3-10                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          1,117,184\n",
      "│    │    └─Bottleneck (3): 3-11                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          1,117,184\n",
      "│    │    └─Bottleneck (4): 3-12                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          1,117,184\n",
      "│    │    └─Bottleneck (5): 3-13                        [10, 1024, 2, 2]          [10, 1024, 2, 2]          1,117,184\n",
      "│    └─Sequential (7): 2-8                              [10, 1024, 2, 2]          [10, 2048, 1, 1]          --\n",
      "│    │    └─Bottleneck (0): 3-14                        [10, 1024, 2, 2]          [10, 2048, 1, 1]          6,039,552\n",
      "│    │    └─Bottleneck (1): 3-15                        [10, 2048, 1, 1]          [10, 2048, 1, 1]          4,462,592\n",
      "│    │    └─Bottleneck (2): 3-16                        [10, 2048, 1, 1]          [10, 2048, 1, 1]          4,462,592\n",
      "│    └─AdaptiveAvgPool2d (8): 2-9                       [10, 2048, 1, 1]          [10, 2048, 1, 1]          --\n",
      "│    └─Flatten (9): 2-10                                [10, 2048, 1, 1]          [10, 2048]                --\n",
      "==================================================================================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 792.13\n",
      "==================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 31.99\n",
      "Params size (MB): 94.03\n",
      "Estimated Total Size (MB): 126.12\n",
      "==================================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "Sequential (Sequential)                  [10, 2048]                [10, 1]                   --\n",
      "├─Linear (0): 1-1                        [10, 2048]                [10, 32]                  65,568\n",
      "├─ReLU (1): 1-2                          [10, 32]                  [10, 32]                  --\n",
      "├─Linear (2): 1-3                        [10, 32]                  [10, 1]                   33\n",
      "===================================================================================================================\n",
      "Total params: 65,601\n",
      "Trainable params: 65,601\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.66\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.26\n",
      "Estimated Total Size (MB): 0.35\n",
      "===================================================================================================================\n",
      "=======================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #\n",
      "=======================================================================================================================================\n",
      "TargetClassifier (TargetClassifier)                          [10, 3, 28, 28]           [10, 10]                  --\n",
      "├─FeatureExtractor (target_feature_extractor): 1-1           [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    └─Sequential (model): 2-1                               [10, 3, 28, 28]           [10, 2048]                --\n",
      "│    │    └─Conv2d (0): 3-1                                  [10, 3, 28, 28]           [10, 64, 14, 14]          (9,408)\n",
      "│    │    └─BatchNorm2d (1): 3-2                             [10, 64, 14, 14]          [10, 64, 14, 14]          (128)\n",
      "│    │    └─ReLU (2): 3-3                                    [10, 64, 14, 14]          [10, 64, 14, 14]          --\n",
      "│    │    └─MaxPool2d (3): 3-4                               [10, 64, 14, 14]          [10, 64, 7, 7]            --\n",
      "│    │    └─Sequential (4): 3-5                              [10, 64, 7, 7]            [10, 256, 7, 7]           (215,808)\n",
      "│    │    └─Sequential (5): 3-6                              [10, 256, 7, 7]           [10, 512, 4, 4]           (1,219,584)\n",
      "│    │    └─Sequential (6): 3-7                              [10, 512, 4, 4]           [10, 1024, 2, 2]          (7,098,368)\n",
      "│    │    └─Sequential (7): 3-8                              [10, 1024, 2, 2]          [10, 2048, 1, 1]          (14,964,736)\n",
      "│    │    └─AdaptiveAvgPool2d (8): 3-9                       [10, 2048, 1, 1]          [10, 2048, 1, 1]          --\n",
      "│    │    └─Flatten (9): 3-10                                [10, 2048, 1, 1]          [10, 2048]                --\n",
      "├─Classifier (classifier): 1-2                               [10, 2048]                [10, 10]                  --\n",
      "│    └─Sequential (model): 2-2                               [10, 2048]                [10, 10]                  --\n",
      "│    │    └─Linear (0): 3-11                                 [10, 2048]                [10, 32]                  (65,568)\n",
      "│    │    └─ReLU (1): 3-12                                   [10, 32]                  [10, 32]                  --\n",
      "│    │    └─Linear (2): 3-13                                 [10, 32]                  [10, 10]                  (330)\n",
      "=======================================================================================================================================\n",
      "Total params: 23,573,930\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,573,930\n",
      "Total mult-adds (M): 792.79\n",
      "=======================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 31.99\n",
      "Params size (MB): 94.30\n",
      "Estimated Total Size (MB): 126.38\n",
      "=======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "sc = SourceClassifier(num_classes=10)\n",
    "print(sc.summary())\n",
    "\n",
    "ad = AdversarialAdapter(sc.feature_extractor, 5, 1, 10)\n",
    "print(ad.summary())\n",
    "\n",
    "tc = TargetClassifier(ad.target_feature_extractor, sc.classifier)\n",
    "print(tc.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6fb771",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffec719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_source_classifier(max_epochs: int, tags: list[str], gpu_num: list[int], source: str,\n",
    "                            model_class, model_kwargs: dict, model_desc: str, batch_size: int):\n",
    "    seed_everything(0, workers=True)\n",
    "    folder_name = f'run_{datetime.utcnow().isoformat(sep=\"T\", timespec=\"microseconds\")}'\n",
    "    results_dir = project_dir + f'domain_adap/adda/mnist_usps/results/{folder_name}/'\n",
    "    os.makedirs(results_dir, exist_ok=False)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/source_loss', mode='min', dirpath=results_dir,\n",
    "                                          filename=f'{source}-source-classifier-best')\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs', default_hp_metric=False)\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs, callbacks=[checkpoint_callback],\n",
    "                      logger=[tf_logger], log_every_n_steps=1, num_sanity_val_steps=0, deterministic=True,\n",
    "                      limit_train_batches=6, limit_val_batches=6, limit_test_batches=6,\n",
    "                      **trainer_kwargs)\n",
    "\n",
    "    # DataLoaders and Datasets\n",
    "    train_ds = get_dataset(source, train=True)\n",
    "    val_ds = get_dataset(source, train=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = model_class(**model_kwargs)\n",
    "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    trainer.test(dataloaders=val_dl, ckpt_path='best')\n",
    "\n",
    "    summary = model.summary() + '\\n' + model_desc\n",
    "    with open(results_dir + 'source_classifier_model_desc.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    gc.collect()\n",
    "    return folder_name\n",
    "\n",
    "\n",
    "def get_train_test_dl(dataset, batch_size):\n",
    "    train_ds = get_dataset(dataset, train=True)\n",
    "    val_ds = get_dataset(dataset, train=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
    "    return train_dl, val_dl\n",
    "\n",
    "\n",
    "def train_target_featurer(max_epochs: int, tags: list[str], gpu_num: list[int], source: str, target: str,\n",
    "                          model_class, model_kwargs: dict, model_desc: str,\n",
    "                          folder_name: str, src_model_class, batch_size: int):\n",
    "    seed_everything(0, workers=True)\n",
    "    results_dir = project_dir + f'domain_adap/adda/mnist_usps/results/{folder_name}/'\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/emd', mode='min', dirpath=results_dir,\n",
    "                                          filename=f'{source}-{target}-adapter-best')\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs', default_hp_metric=False)\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs, callbacks=[checkpoint_callback],\n",
    "                      logger=[tf_logger], log_every_n_steps=1, num_sanity_val_steps=0, deterministic=True,\n",
    "                      limit_train_batches=6, limit_val_batches=6, limit_test_batches=6,\n",
    "                      **trainer_kwargs)\n",
    "\n",
    "    # DataLoaders and Datasets\n",
    "    src_train_dl, src_val_dl = get_train_test_dl(source, batch_size)\n",
    "    tar_train_dl, tar_val_dl = get_train_test_dl(target, batch_size)\n",
    "\n",
    "    train_dl = {\n",
    "        'source': src_train_dl,\n",
    "        'target': tar_train_dl,\n",
    "    }\n",
    "    val_dl = CombinedLoader({\n",
    "        'source': src_val_dl,\n",
    "        'target': tar_val_dl,\n",
    "    }, mode='max_size_cycle')\n",
    "\n",
    "    src_model = src_model_class.load_from_checkpoint(results_dir + f'{source}-source-classifier-best.ckpt')\n",
    "    model = model_class(source_feature_extractor=src_model.feature_extractor, **model_kwargs)\n",
    "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    trainer.test(dataloaders=val_dl, ckpt_path='best')\n",
    "\n",
    "    summary = model.summary() + '\\n' + model_desc\n",
    "    with open(results_dir + 'adapter_model_desc.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "def test_target_classifier(source: str, target: str, gpu_num: list[int], model_class, model_kwargs: dict,\n",
    "                           folder_name: str, src_model_class, adap_model_class, batch_size, adap_fname_suffix: str):\n",
    "    results_dir = project_dir + f'domain_adap/adda/mnist_usps/results/{folder_name}/'\n",
    "\n",
    "    val_ds = get_dataset(target, train=False)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    src_model = src_model_class.load_from_checkpoint(results_dir + f'{source}-source-classifier-best.ckpt')\n",
    "    adap_model = adap_model_class.load_from_checkpoint(results_dir + f'{source}-{target}-adapter-best{adap_fname_suffix}.ckpt',\n",
    "                                                       source_feature_extractor=src_model.feature_extractor)\n",
    "    model = model_class(target_feature_extractor=adap_model.target_feature_extractor, classifier=src_model.classifier,\n",
    "                        **model_kwargs)\n",
    "\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, enable_checkpointing=False, num_sanity_val_steps=0,\n",
    "                      limit_train_batches=6, limit_val_batches=6, limit_test_batches=6, limit_predict_batches=6,\n",
    "                      deterministic=True, **trainer_kwargs)\n",
    "    pred_results = trainer.predict(model, dataloaders=val_dl)\n",
    "    all_y, all_y_hat = split_results(pred_results)\n",
    "    loss = CrossEntropyLoss()(all_y_hat, all_y).item()\n",
    "    acc = accuracy(all_y_hat, all_y, average='macro', num_classes=src_model.classifier.num_classes, multiclass=True).item()\n",
    "    print(f'Target Test Loss: {loss}, Target Test Acc: {acc}')\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dc88e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | classifier        | Classifier       | 65.9 K\n",
      "-------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.296    Total estimated model params size (MB)\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013349056243896484,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68b6bc3572e461289175b92417b4e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00734710693359375,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007630109786987305,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:43.887324/mnist-source-classifier-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:43.887324/mnist-source-classifier-best.ckpt\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007425785064697266,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726509ed50bb4095815c5fd082b4e427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/source_acc        0.0833333358168602\n",
      "    test/source_loss         2.89630126953125\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:43.887324 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name                     | Type             | Params\n",
      "--------------------------------------------------------------\n",
      "0 | source_feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | target_feature_extractor | FeatureExtractor | 23.5 M\n",
      "2 | critic                   | Sequential       | 65.6 K\n",
      "--------------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "47.1 M    Total params\n",
      "188.327   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007485866546630859,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad23e1a82053407293deb711fa6c1acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0073490142822265625,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007451772689819336,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:43.887324/mnist-usps-adapter-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:43.887324/mnist-usps-adapter-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007898092269897461,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d4d8019f9041e9a70153a15be3df36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/actual_emd        0.7282901406288147\n",
      "    test/critic_loss        -0.7282901406288147\n",
      "        test/emd            0.7282901406288147\n",
      "      test/gen_loss         0.2855997383594513\n",
      "         test/gp             0.761939525604248\n",
      "    test/source_score        0.442690372467041\n",
      "    test/target_score       -0.2855997383594513\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008095026016235352,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fc9f2cb1f7402586464ec54702302b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Test Loss: 3.1491940021514893, Target Test Acc: 0.0476190522313118\n"
     ]
    }
   ],
   "source": [
    "source = 'mnist'\n",
    "target = 'usps'\n",
    "\n",
    "folder_name = train_source_classifier(2, [], [], source, SourceClassifier, dict(num_classes=10),\n",
    "                                      'Source classifier training', batch_size=2)\n",
    "train_target_featurer(2, [], [], source, target, AdversarialAdapter,\n",
    "                      dict(ncritic=5, ngen=1, penalty_weight=10), 'Adversarial adapter training',\n",
    "                      folder_name, SourceClassifier, batch_size=2)\n",
    "loss, acc = test_target_classifier(source, target, [], TargetClassifier, dict(), folder_name,\n",
    "                                   SourceClassifier, AdversarialAdapter, batch_size=2, adap_fname_suffix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcb8a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | classifier        | Classifier       | 65.9 K\n",
      "-------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.296    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007433891296386719,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b27e73e58884ea496dec0ad6cd347c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007498979568481445,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0074579715728759766,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:54.722056/usps-source-classifier-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:54.722056/usps-source-classifier-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008018016815185547,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a61452c77f41c8b42d868323e8c4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/source_acc        0.0833333358168602\n",
      "    test/source_loss         7.793001174926758\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:54.722056 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name                     | Type             | Params\n",
      "--------------------------------------------------------------\n",
      "0 | source_feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | target_feature_extractor | FeatureExtractor | 23.5 M\n",
      "2 | critic                   | Sequential       | 65.6 K\n",
      "--------------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "47.1 M    Total params\n",
      "188.327   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00775909423828125,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991bac9c1a364921afb7e055bf16c942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007315158843994141,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007477998733520508,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:54.722056/usps-mnist-adapter-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/mnist_usps/results/run_2022-11-09T18:53:54.722056/usps-mnist-adapter-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0076448917388916016,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4158216ee1407e9bde9b520f3e9cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/actual_emd         10.93496322631836\n",
      "    test/critic_loss        -10.93496322631836\n",
      "        test/emd             10.93496322631836\n",
      "      test/gen_loss         1.4190748929977417\n",
      "         test/gp            1.2281850576400757\n",
      "    test/source_score        9.515888214111328\n",
      "    test/target_score       -1.4190748929977417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0077588558197021484,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b5efb0ba054703a4360f544ee07ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Test Loss: 2.906193971633911, Target Test Acc: 0.1111111119389534\n"
     ]
    }
   ],
   "source": [
    "source = 'usps'\n",
    "target = 'mnist'\n",
    "\n",
    "folder_name = train_source_classifier(2, [], [], source, SourceClassifier, dict(num_classes=10),\n",
    "                                      'Source classifier training', batch_size=2)\n",
    "train_target_featurer(2, [], [], source, target, AdversarialAdapter,\n",
    "                      dict(ncritic=5, ngen=1, penalty_weight=10), 'Adversarial adapter training',\n",
    "                      folder_name, SourceClassifier, batch_size=2)\n",
    "loss, acc = test_target_classifier(source, target, [], TargetClassifier, dict(), folder_name,\n",
    "                                   SourceClassifier, AdversarialAdapter, batch_size=2, adap_fname_suffix='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a58dc1",
   "metadata": {},
   "source": [
    "# Clipart - RealWorld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451be0c",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29b9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(Module):\n",
    "    \"\"\"Resnet based feature extractor\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        backbone = resnet50(pretrained=True)\n",
    "        layers = list(backbone.children())[:-1]  # Until AdaptiveAvgPool2d Layer\n",
    "        self.model = Sequential(\n",
    "            *layers,\n",
    "            Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: batch of images\n",
    "        :return: batch of 2048 dim vectors\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Classifier(Module):\n",
    "    \"\"\"A simple classifier\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = Sequential(\n",
    "            Linear(in_features=2048, out_features=num_classes),  # Output Logits\n",
    "        )\n",
    "        seed_everything(0)\n",
    "        init.xavier_uniform_(self.model[0].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class SourceClassifier(LightningModule):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(SourceClassifier, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.classifier = Classifier(num_classes)\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def _common_step(self, batch, btype):\n",
    "        not_training = btype != 'train'\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = CrossEntropyLoss()(y_hat, y)\n",
    "        acc = accuracy(y_hat, y, average='macro', num_classes=self.num_classes, multiclass=True)\n",
    "        self.log(f'{btype}/source_loss', loss, on_step=False, on_epoch=True, sync_dist=not_training)\n",
    "        self.log(f'{btype}/source_acc', acc, on_step=False, on_epoch=True, sync_dist=not_training)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._common_step(batch, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._common_step(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                              row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        source_imgs = torch.randn((10, 3, 256, 256), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self, input_data=source_imgs, **summary_kwargs))\n",
    "        return summary_string\n",
    "\n",
    "\n",
    "class AdversarialAdapter(LightningModule):\n",
    "\n",
    "    def __init__(self, source_feature_extractor: FeatureExtractor, ncritic, ngen, penalty_weight):\n",
    "        \"\"\"\n",
    "        :param source_feature_extractor: trained source feature extractor. its weights will not be updated here.\n",
    "        \"\"\"\n",
    "        super(AdversarialAdapter, self).__init__()\n",
    "        self.save_hyperparameters(ignore=['source_feature_extractor'])\n",
    "        self.ncritic = ncritic\n",
    "        self.ngen = ngen\n",
    "        self.penalty_weight = penalty_weight\n",
    "\n",
    "        self.source_feature_extractor = FeatureExtractor()  # this works as the real samples\n",
    "        self.source_feature_extractor.load_state_dict(source_feature_extractor.state_dict())\n",
    "        self.source_feature_extractor.requires_grad_(False)\n",
    "        self.target_feature_extractor = FeatureExtractor()  # this works as the generator - which needs to be trained\n",
    "        self.target_feature_extractor.load_state_dict(source_feature_extractor.state_dict())\n",
    "\n",
    "        self.critic = Sequential(\n",
    "            Linear(in_features=2048, out_features=32),\n",
    "            ReLU(),\n",
    "            Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "        seed_everything(0)\n",
    "        init.kaiming_normal_(self.critic[0].weight, nonlinearity='relu')\n",
    "        init.xavier_uniform_(self.critic[2].weight)\n",
    "        self.float()\n",
    "\n",
    "    def _gradient_penalty(self, batch):\n",
    "        source_imgs, target_imgs = batch['source'][0], batch['target'][0]\n",
    "        batch_size = source_imgs.shape[0]\n",
    "        source_features = self.source_feature_extractor(source_imgs)\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        eps = torch.rand(batch_size, 1, device=self.device)\n",
    "        eps = eps.expand_as(source_features)\n",
    "        interpolated = eps * source_features + (1 - eps) * target_features\n",
    "        interpolated.requires_grad_(True)\n",
    "        interpolated_scores = self.critic(interpolated)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=interpolated_scores,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(interpolated_scores),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradients_norm = gradients.norm(2, 1)  # norm of gradient each of the samples\n",
    "        penalty = (gradients_norm - 1) ** 2  # penalty for each sample\n",
    "        gp = self.penalty_weight * penalty.mean()  # mean across samples\n",
    "        return gp\n",
    "\n",
    "    def _critic_loss(self, batch):\n",
    "        source_imgs, target_imgs = batch['source'][0], batch['target'][0]\n",
    "        source_features = self.source_feature_extractor(source_imgs)\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        source_score = self.critic(source_features).mean()  # \"real\"\n",
    "        target_score = self.critic(target_features).mean()  # \"fake\"\n",
    "        critic_loss = target_score - source_score  # \"fake\" - \"real\"\n",
    "        return critic_loss, source_score, target_score\n",
    "\n",
    "    def _gen_loss(self, batch):\n",
    "        target_imgs = batch['target'][0]\n",
    "        target_features = self.target_feature_extractor(target_imgs)\n",
    "        target_score = self.critic(target_features).mean()\n",
    "        gen_loss = -target_score\n",
    "        return gen_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        self.source_feature_extractor.eval()\n",
    "        if optimizer_idx == 1:  # Critic optimizer - only update Critic weights\n",
    "            critic_loss, source_score, target_score = self._critic_loss(batch)\n",
    "            gp = self._gradient_penalty(batch)\n",
    "            self.log(f'train/critic_loss', critic_loss, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/gp', gp, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/source_score', source_score, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            self.log(f'train/target_score', target_score, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            return critic_loss + gp\n",
    "\n",
    "        if optimizer_idx == 0:  # Generator optimizer - only update Generator weights\n",
    "            gen_loss = self._gen_loss(batch)\n",
    "            self.log(f'train/gen_loss', gen_loss, on_step=False, on_epoch=True, sync_dist=False)\n",
    "            return gen_loss\n",
    "\n",
    "        raise Exception(f'Unknown optimizer index: {optimizer_idx}')\n",
    "\n",
    "    def _shared_eval(self, batch, btype):\n",
    "        critic_loss, source_score, target_score = self._critic_loss(batch)\n",
    "        emd = torch.abs(critic_loss)\n",
    "        actual_emd = -critic_loss\n",
    "        self.log(f'{btype}/actual_emd', actual_emd, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/emd', emd, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/critic_loss', critic_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/source_score', source_score, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/target_score', target_score, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        gp = self._gradient_penalty(batch)\n",
    "        gen_loss = self._gen_loss(batch)\n",
    "        self.log(f'{btype}/gp', gp, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(f'{btype}/gen_loss', gen_loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._shared_eval(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        torch.set_grad_enabled(True)\n",
    "        self._shared_eval(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        generator_opt = Adam(params=self.target_feature_extractor.parameters(), lr=0.0001, betas=(0, 0.9))\n",
    "        critic_opt = Adam(params=self.critic.parameters(), lr=0.0001, betas=(0, 0.9))\n",
    "        return (\n",
    "            {\"optimizer\": generator_opt, \"frequency\": self.ngen},\n",
    "            {\"optimizer\": critic_opt, \"frequency\": self.ncritic},\n",
    "        )\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                             row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        source_imgs = torch.randn((10, 3, 256, 256), dtype=torch.float)\n",
    "        target_imgs = torch.randn((10, 3, 256, 256), dtype=torch.float)\n",
    "        features = torch.randn((10, 2048), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self.source_feature_extractor, input_data=source_imgs, **summary_kwargs)) + '\\n' + \\\n",
    "                         str(summary(model=self.target_feature_extractor, input_data=target_imgs, **summary_kwargs)) + '\\n' + \\\n",
    "                         str(summary(model=self.critic, input_data=features, **summary_kwargs))\n",
    "        return summary_string\n",
    "\n",
    "\n",
    "class TargetClassifier(LightningModule):\n",
    "    \"\"\"For the sake of completion\"\"\"\n",
    "\n",
    "    def __init__(self, target_feature_extractor: FeatureExtractor, classifier: Classifier):\n",
    "        super(TargetClassifier, self).__init__()\n",
    "        self.save_hyperparameters(ignore=['target_feature_extractor', 'classifier'])\n",
    "        self.target_feature_extractor = target_feature_extractor\n",
    "        self.classifier = classifier\n",
    "        self.target_feature_extractor.requires_grad_(False)\n",
    "        self.classifier.requires_grad_(False)\n",
    "\n",
    "    def forward(self, target_imgs):\n",
    "        features = self.target_feature_extractor(target_imgs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return y.detach(), y_hat.detach()\n",
    "\n",
    "    def summary(self) -> str:\n",
    "        summary_kwargs = dict(dtypes=[torch.float], depth=4, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                              row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "        target_imgs = torch.randn((10, 3, 256, 256), dtype=torch.float)\n",
    "        summary_string = str(summary(model=self, input_data=target_imgs, **summary_kwargs))\n",
    "        return summary_string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f650c",
   "metadata": {},
   "source": [
    "## Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22859dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_source_classifier(max_epochs: int, tags: list[str], gpu_num: list[int], source: str,\n",
    "                            model_class, model_kwargs: dict, model_desc: str, batch_size: int):\n",
    "    seed_everything(0, workers=True)\n",
    "    folder_name = f'run_{datetime.utcnow().isoformat(sep=\"T\", timespec=\"microseconds\")}'\n",
    "    results_dir = project_dir + f'domain_adap/adda/office_home/results/{folder_name}/'\n",
    "    os.makedirs(results_dir, exist_ok=False)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/source_loss', mode='min', dirpath=results_dir,\n",
    "                                          filename=f'{source}-source-classifier-best')\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs', default_hp_metric=False)\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs, callbacks=[checkpoint_callback],\n",
    "                      logger=[tf_logger], log_every_n_steps=1, num_sanity_val_steps=0, deterministic=True,\n",
    "                      limit_train_batches=3, limit_val_batches=3, limit_test_batches=3,\n",
    "                      **trainer_kwargs)\n",
    "\n",
    "    # DataLoaders and Datasets\n",
    "    train_ds = get_dataset(source, train=True)\n",
    "    val_ds = get_dataset(source, train=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=num_cpus)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=num_cpus)\n",
    "\n",
    "    model = model_class(**model_kwargs)\n",
    "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    trainer.test(dataloaders=val_dl, ckpt_path='best')\n",
    "\n",
    "    summary = model.summary() + '\\n' + model_desc\n",
    "    with open(results_dir + 'source_classifier_model_desc.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    gc.collect()\n",
    "    return folder_name\n",
    "\n",
    "\n",
    "def get_train_test_dl(dataset, batch_size):\n",
    "    train_ds = get_dataset(dataset, train=True)\n",
    "    val_ds = get_dataset(dataset, train=False)\n",
    "    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=num_cpus, drop_last=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=num_cpus, drop_last=True)\n",
    "    return train_dl, val_dl\n",
    "\n",
    "\n",
    "def train_target_featurer(max_epochs: int, tags: list[str], gpu_num: list[int], source: str, target: str,\n",
    "                          model_class, model_kwargs: dict, model_desc: str,\n",
    "                          folder_name: str, src_model_class, batch_size: int):\n",
    "    seed_everything(0, workers=True)\n",
    "    results_dir = project_dir + f'domain_adap/adda/office_home/results/{folder_name}/'\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/emd', mode='min', dirpath=results_dir,\n",
    "                                          filename=f'{source}-{target}-adapter-best')\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs', default_hp_metric=False)\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs, callbacks=[checkpoint_callback],\n",
    "                      logger=[tf_logger], log_every_n_steps=1, num_sanity_val_steps=0, deterministic=True,\n",
    "                      limit_train_batches=3, limit_val_batches=3, limit_test_batches=3,\n",
    "                      **trainer_kwargs)\n",
    "\n",
    "    # DataLoaders and Datasets\n",
    "    src_train_dl, src_val_dl = get_train_test_dl(source, batch_size)\n",
    "    tar_train_dl, tar_val_dl = get_train_test_dl(target, batch_size)\n",
    "\n",
    "    train_dl = {\n",
    "        'source': src_train_dl,\n",
    "        'target': tar_train_dl,\n",
    "    }\n",
    "    val_dl = CombinedLoader({\n",
    "        'source': src_val_dl,\n",
    "        'target': tar_val_dl,\n",
    "    }, mode='max_size_cycle')\n",
    "\n",
    "    src_model = src_model_class.load_from_checkpoint(results_dir + f'{source}-source-classifier-best.ckpt')\n",
    "    model = model_class(source_feature_extractor=src_model.feature_extractor, **model_kwargs)\n",
    "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    trainer.test(dataloaders=val_dl, ckpt_path='best')\n",
    "\n",
    "    summary = model.summary() + '\\n' + model_desc\n",
    "    with open(results_dir + 'adapter_model_desc.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def test_target_classifier(source: str, target: str, gpu_num: list[int], model_class, model_kwargs: dict,\n",
    "                           folder_name: str, src_model_class, adap_model_class, batch_size):\n",
    "    results_dir = project_dir + f'domain_adap/adda/office_home/results/{folder_name}/'\n",
    "\n",
    "    val_ds = get_dataset(target, train=False)\n",
    "    val_dl = DataLoader(val_ds, batch_size, shuffle=False, num_workers=num_cpus)\n",
    "\n",
    "    src_model = src_model_class.load_from_checkpoint(results_dir + f'{source}-source-classifier-best.ckpt')\n",
    "    adap_model = adap_model_class.load_from_checkpoint(results_dir + f'{source}-{target}-adapter-best.ckpt',\n",
    "                                                       source_feature_extractor=src_model.feature_extractor)\n",
    "    model = model_class(target_feature_extractor=adap_model.target_feature_extractor, classifier=src_model.classifier,\n",
    "                        **model_kwargs)\n",
    "\n",
    "    trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num) if use_gpu else dict()\n",
    "    trainer = Trainer(default_root_dir=results_dir, enable_checkpointing=False, num_sanity_val_steps=0,\n",
    "                      limit_train_batches=3, limit_val_batches=3, limit_test_batches=3, limit_predict_batches=3,\n",
    "                      deterministic=True, **trainer_kwargs)\n",
    "    pred_results = trainer.predict(model, dataloaders=val_dl)\n",
    "    all_y, all_y_hat = split_results(pred_results)\n",
    "    loss = CrossEntropyLoss()(all_y_hat, all_y).item()\n",
    "    acc = accuracy(all_y_hat, all_y, average='macro', num_classes=src_model.classifier.num_classes, multiclass=True).item()\n",
    "    print(f'Target Test Loss: {loss}, Target Test Acc: {acc}')\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2571e44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | classifier        | Classifier       | 133 K \n",
      "-------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.565    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007403850555419922,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449a5014614740519ed4652bb353c2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0077817440032958984,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02578902244567871,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:54:06.558872/clipart-source-classifier-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:54:06.558872/clipart-source-classifier-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008126974105834961,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ac8184821c46d89e653d01e4e47669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/source_acc                0.0\n",
      "    test/source_loss        10.394278526306152\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:54:06.558872 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name                     | Type             | Params\n",
      "--------------------------------------------------------------\n",
      "0 | source_feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | target_feature_extractor | FeatureExtractor | 23.5 M\n",
      "2 | critic                   | Sequential       | 65.6 K\n",
      "--------------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "47.1 M    Total params\n",
      "188.327   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0075070858001708984,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f0531aa6f94d30866ef79cba667036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00913691520690918,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008391380310058594,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:54:06.558872/clipart-realworld-adapter-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:54:06.558872/clipart-realworld-adapter-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01635003089904785,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a6be28e4ad4a61b14372c350976b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/actual_emd        -0.5873987674713135\n",
      "    test/critic_loss        0.5873987674713135\n",
      "        test/emd            0.5873987674713135\n",
      "      test/gen_loss          1.475451111793518\n",
      "         test/gp            0.49851155281066895\n",
      "    test/source_score       -2.062849760055542\n",
      "    test/target_score       -1.475451111793518\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008369922637939453,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6346cb71d55481f963ec82783585400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Test Loss: 3.0300331115722656, Target Test Acc: 0.055555559694767\n"
     ]
    }
   ],
   "source": [
    "source = 'clipart'\n",
    "target = 'realworld'\n",
    "\n",
    "folder_name = train_source_classifier(2, [], [], source, SourceClassifier, dict(num_classes=65),\n",
    "                                      'Source classifier training', batch_size=2)\n",
    "\n",
    "train_target_featurer(2, [], [], source, target, AdversarialAdapter,\n",
    "                      dict(ncritic=2, ngen=1, penalty_weight=10), 'Adversarial adapter training',\n",
    "                      folder_name, SourceClassifier, batch_size=2)\n",
    "\n",
    "loss, acc = test_target_classifier(source, target, [], TargetClassifier, dict(), folder_name,\n",
    "                                   SourceClassifier, AdversarialAdapter, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf37e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "\n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | classifier        | Classifier       | 133 K \n",
      "-------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 M    Total params\n",
      "94.565    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008317947387695312,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c69abe712540c697747d6564346292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0074689388275146484,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025935888290405273,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:56:53.860460/realworld-source-classifier-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:56:53.860460/realworld-source-classifier-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009410619735717773,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ae7d71bc304f178a2e66e5f1b9beda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/source_acc                0.0\n",
      "    test/source_loss         6.329334259033203\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "/Users/rajjain/miniforge3/envs/gpfa_latents/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:56:53.860460 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name                     | Type             | Params\n",
      "--------------------------------------------------------------\n",
      "0 | source_feature_extractor | FeatureExtractor | 23.5 M\n",
      "1 | target_feature_extractor | FeatureExtractor | 23.5 M\n",
      "2 | critic                   | Sequential       | 65.6 K\n",
      "--------------------------------------------------------------\n",
      "23.6 M    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "47.1 M    Total params\n",
      "188.327   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0077571868896484375,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f6e98f993b47a990b2bb68a9d58b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011362791061401367,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007838010787963867,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:56:53.860460/realworld-clipart-adapter-best.ckpt\n",
      "Loaded model weights from checkpoint at /Users/rajjain/PycharmProjects/ADRL-Course-Work/domain_adap/adda/office_home/results/run_2022-11-09T18:56:53.860460/realworld-clipart-adapter-best.ckpt\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016134977340698242,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df36fd846b854121a3fa7b756b2d4d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test/actual_emd        0.28046733140945435\n",
      "    test/critic_loss       -0.28046733140945435\n",
      "        test/emd            0.28046733140945435\n",
      "      test/gen_loss         -0.5411401391029358\n",
      "         test/gp            2.7320668697357178\n",
      "    test/source_score       0.8216074109077454\n",
      "    test/target_score       0.5411401391029358\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008489131927490234,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 9,
       "postfix": null,
       "prefix": "Predicting",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8930d4ff092d427baed11aa66d335e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Test Loss: 7.870952129364014, Target Test Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "source = 'realworld'\n",
    "target = 'clipart'\n",
    "\n",
    "folder_name = train_source_classifier(2, [], [], source, SourceClassifier, dict(num_classes=65),\n",
    "                                      'Source classifier training', batch_size=2)\n",
    "\n",
    "train_target_featurer(2, [], [], source, target, AdversarialAdapter,\n",
    "                      dict(ncritic=2, ngen=1, penalty_weight=10), 'Adversarial adapter training',\n",
    "                      folder_name, SourceClassifier, batch_size=2)\n",
    "\n",
    "loss, acc = test_target_classifier(source, target, [], TargetClassifier, dict(), folder_name,\n",
    "                                   SourceClassifier, AdversarialAdapter, batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
