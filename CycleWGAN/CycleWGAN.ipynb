{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18e1c32",
   "metadata": {},
   "source": [
    "### General Settings\n",
    "\n",
    "Change the respective settings to run appropriately\n",
    "\n",
    "Use `limit_train_batches`, `limit_val_batches`, `limit_test_batches` as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4174788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Users/rajjain/PycharmProjects/ADRL-Course-Work/'\n",
    "data_dir = project_dir + 'data/'\n",
    "celeba_data_dir = '/Users/rajjain/Desktop/CourseWork/CelebA/'\n",
    "bitmoji_data_dir = '/Users/rajjain/Desktop/CourseWork/Bitmoji/'\n",
    "mnist_data_dir = '/Users/rajjain/Desktop/CourseWork/MNIST/'\n",
    "svhn_data_dir = '/Users/rajjain/Desktop/CourseWork/SVHN/'\n",
    "use_gpu = False\n",
    "num_cpus = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b053374",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc30995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init, Linear, Sequential, Conv2d, PReLU, Module, BatchNorm2d, ConvTranspose2d, Hardtanh, \\\n",
    "    Flatten, MaxPool2d, L1Loss\n",
    "from torchvision.datasets import CelebA, ImageFolder, SVHN, MNIST\n",
    "from pytorch_lightning.trainer.supporters import CombinedLoader\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import LightningModule\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision import transforms\n",
    "from torch.optim import RMSprop\n",
    "from datetime import datetime\n",
    "from torchinfo import summary\n",
    "from glob import glob\n",
    "import itertools\n",
    "import pandas\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72342330",
   "metadata": {},
   "source": [
    "### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22bcf37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    imgs = torch.stack([elem[0] for elem in batch])\n",
    "    return [imgs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbde596",
   "metadata": {},
   "source": [
    "# Cycle WGAN for CelebA - Bitmoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b976b5b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a249a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C2BGenerator(Module):\n",
    "    \"\"\"\n",
    "    Take CelebA image [-1, 1] and generate \"fake\" Bitmoji image [-1, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(C2BGenerator, self).__init__()\n",
    "        self.model = Sequential(\n",
    "            # Downsampling part\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=8, kernel_size=(4, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            Conv2d(in_channels=8, out_channels=10, kernel_size=(6, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            Conv2d(in_channels=10, out_channels=12, kernel_size=(10, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=14, kernel_size=(15, 6), stride=(3, 3)),\n",
    "            PReLU(num_parameters=14, init=0.25),\n",
    "            BatchNorm2d(num_features=14),\n",
    "\n",
    "            # Upsampling part\n",
    "            ConvTranspose2d(in_channels=14, out_channels=12, kernel_size=(4, 8), stride=(2, 2)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            ConvTranspose2d(in_channels=12, out_channels=10, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            ConvTranspose2d(in_channels=10, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            ConvTranspose2d(in_channels=8, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            ConvTranspose2d(in_channels=6, out_channels=3, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            Hardtanh(min_val=-1, max_val=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 27, 3):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['27'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class B2CGenerator(Module):\n",
    "    \"\"\"\n",
    "    Take Bitmoji image [-1, 1] and generate \"fake\" CelebA image [-1, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(B2CGenerator, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            # Downsampling part\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            Conv2d(in_channels=10, out_channels=12, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=14, kernel_size=(4, 8), stride=(2, 2)),\n",
    "            PReLU(num_parameters=14, init=0.25),\n",
    "            BatchNorm2d(num_features=14),\n",
    "\n",
    "            # Upsampling part\n",
    "            ConvTranspose2d(in_channels=14, out_channels=12, kernel_size=(15, 6), stride=(3, 3), \n",
    "                            output_padding=(1, )),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            ConvTranspose2d(in_channels=12, out_channels=10, kernel_size=(10, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            ConvTranspose2d(in_channels=10, out_channels=8, kernel_size=(6, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            ConvTranspose2d(in_channels=8, out_channels=6, kernel_size=(4, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            ConvTranspose2d(in_channels=6, out_channels=3, kernel_size=(3, 2), stride=(1, 1)),\n",
    "            Hardtanh(min_val=-1, max_val=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 27, 3):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['27'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CriticB(Module):\n",
    "    \"\"\"\n",
    "    Critic for Bitmoji images - Checks if the bitmoji image passed is from bitmoji \"real\" data distribution or from \n",
    "    \"fake\" C2B generator\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CriticB, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=60, out_features=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 13, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['17'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CriticC(Module):\n",
    "    \"\"\"\n",
    "    Critic for CelebA images - Checks if the celeba image passed is from celeba \"real\" data distribution or from \n",
    "    \"fake\" B2C generator\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CriticC, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Conv2d(in_channels=9, out_channels=12, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            Conv2d(in_channels=12, out_channels=15, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=15, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=15),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=225, out_features=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 13, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['17'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CBCycleWGAN(LightningModule):\n",
    "\n",
    "    def __init__(self, ncritic, ngen, bs, cycle_weight):\n",
    "        super(CBCycleWGAN, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.ncritic = ncritic\n",
    "        self.ngen = ngen\n",
    "        self.bs = bs\n",
    "        self.cycle_weight = cycle_weight\n",
    "\n",
    "        # CelebA to Bitmoji\n",
    "        self.genC2B = C2BGenerator()\n",
    "        self.criticB = CriticB()\n",
    "\n",
    "        # Bitmoji to CelebA\n",
    "        self.genB2C = B2CGenerator()\n",
    "        self.criticC = CriticC()\n",
    "\n",
    "        # Initialisations\n",
    "        self.genC2B.initialise()\n",
    "        self.criticB.initialise()\n",
    "        self.genB2C.initialise()\n",
    "        self.criticC.initialise()\n",
    "\n",
    "        # CycleGAN authors use image pool to update the discriminator. That was required because GAN training (on the\n",
    "        # usual objective) was unstable. We are using WGAN and hopefully won't get into such issues. Hence, skipping\n",
    "        # keeping the pool of images\n",
    "\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, real_celebas, real_bitmojis):\n",
    "        real_bitmoji_scores = self.criticB(real_bitmojis)\n",
    "        real_celeba_scores = self.criticC(real_celebas)\n",
    "        fake_bitmojis = self.genC2B(real_celebas)\n",
    "        fake_celebas = self.genB2C(real_bitmojis)\n",
    "        return real_celeba_scores, real_bitmoji_scores, fake_celebas, fake_bitmojis\n",
    "\n",
    "    def _critic_losses(self, real_celebas, real_bitmojis, btype):\n",
    "        # WGAN: Critic gets updated from the fake and real data\n",
    "        # CycleGAN: Need to do this for both critics!\n",
    "\n",
    "        # Bitmoji Critic\n",
    "        real_bitmojis_score = self.criticB(real_bitmojis).mean()\n",
    "        fake_bitmojis = self.genC2B(real_celebas)\n",
    "        fake_bitmojis_score = self.criticB(fake_bitmojis).mean()\n",
    "        criticB_loss = fake_bitmojis_score - real_bitmojis_score  # minimise this!\n",
    "\n",
    "        # CelebA Critic\n",
    "        real_celebas_score = self.criticC(real_celebas).mean()\n",
    "        fake_celebas = self.genB2C(real_bitmojis)\n",
    "        fake_celebas_score = self.criticC(fake_celebas).mean()\n",
    "        criticC_loss = fake_celebas_score - real_celebas_score\n",
    "\n",
    "        not_training = btype != 'train'\n",
    "        self.log(f'{btype}/criticB_loss', criticB_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, \n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/criticC_loss', criticC_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, \n",
    "                 sync_dist=not_training)\n",
    "        return criticB_loss, criticC_loss\n",
    "\n",
    "    def _generator_losses(self, real_celebas, real_bitmojis, btype):\n",
    "        # WGAN: Generator gets updates from the fake data\n",
    "        # CycleGAN: Do this for both generators and additionally put cycle consistency loss\n",
    "\n",
    "        # CelebA to Bitmoji\n",
    "        fake_bitmojis = self.genC2B(real_celebas)\n",
    "        fake_bitmojis_score = self.criticB(fake_bitmojis).mean()\n",
    "        genC2B_loss = -fake_bitmojis_score  # minimise this!\n",
    "\n",
    "        # Bitmoji to CelebA\n",
    "        fake_celebas = self.genB2C(real_bitmojis)\n",
    "        fake_celebas_score = self.criticC(fake_celebas).mean()\n",
    "        genB2C_loss = -fake_celebas_score\n",
    "\n",
    "        # Cycle Consistency\n",
    "        # Side Note: *Ideally* L1 norm should be added across dimensions and mean-ed across samples. In their\n",
    "        # implementation, authors have mean-ed across dimensions too, keeping same implementation as them\n",
    "        celeba_identity_loss = L1Loss()(real_celebas, self.genB2C(fake_bitmojis))\n",
    "        bitmoji_identity_loss = L1Loss()(real_bitmojis, self.genC2B(fake_celebas))\n",
    "        cycle_loss = self.cycle_weight * (celeba_identity_loss + bitmoji_identity_loss)\n",
    "\n",
    "        not_training = btype != 'train'\n",
    "        self.log(f'{btype}/genC2B_loss', genC2B_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, \n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/genB2C_loss', genB2C_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, \n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/cycle_loss',  cycle_loss,  on_step=False, on_epoch=True, reduce_fx=torch.mean, \n",
    "                 sync_dist=not_training)\n",
    "        self.log(f'{btype}/celeba_identity_loss',  celeba_identity_loss,  on_step=False, on_epoch=True, \n",
    "                 reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/bitmoji_identity_loss', bitmoji_identity_loss, on_step=False, on_epoch=True, \n",
    "                 reduce_fx=torch.mean, sync_dist=not_training)\n",
    "\n",
    "        return genC2B_loss, genB2C_loss, cycle_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real_celebas, real_bitmojis = batch['celeba'][0], batch['bitmoji'][0]\n",
    "\n",
    "        if optimizer_idx == 1:  # Critic optimizer - only update Critic weights\n",
    "            criticB_loss, criticC_loss = self._critic_losses(real_celebas, real_bitmojis, 'train')\n",
    "            # CycleGAN authors divide this loss by 2 to slow down the rate of critic learning. Here, as the loss is\n",
    "            # wasserstein loss, I believe it may not be required\n",
    "            return criticB_loss + criticC_loss\n",
    "\n",
    "        if optimizer_idx == 0:  # Generator optimizer - only update Generator weights\n",
    "            genC2B_loss, genB2C_loss, cycle_loss = self._generator_losses(real_celebas, real_bitmojis, 'train')\n",
    "            return genC2B_loss + genB2C_loss + cycle_loss\n",
    "\n",
    "        # Is there a way to consolidate the losses and return one per epoch?\n",
    "        raise Exception(f'Unknown optimizer index: {optimizer_idx}')\n",
    "\n",
    "    def _shared_eval(self, batch, btype):\n",
    "        real_celebas, real_bitmojis = batch['celeba'][0], batch['bitmoji'][0]\n",
    "        criticB_loss, criticC_loss = self._critic_losses(real_celebas, real_bitmojis, btype)\n",
    "        genC2B_loss, genB2C_loss, cycle_loss = self._generator_losses(real_celebas, real_bitmojis, btype)\n",
    "        total_loss = criticB_loss + criticC_loss + genC2B_loss + genB2C_loss + cycle_loss\n",
    "        self.log(f'{btype}/loss', total_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Using the strategy from WGAN paper instead of CycleGAN paper!\"\"\"\n",
    "        generator_opt = RMSprop(params=itertools.chain(self.genC2B.parameters(), self.genB2C.parameters()), \n",
    "                                lr=0.00005)\n",
    "        critic_opt = RMSprop(params=itertools.chain(self.criticC.parameters(), self.criticB.parameters()), \n",
    "                             lr=0.00005)\n",
    "        return (\n",
    "            {\"optimizer\": generator_opt, \"frequency\": self.ngen},\n",
    "            {\"optimizer\": critic_opt, \"frequency\": self.ncritic},\n",
    "        )\n",
    "\n",
    "    def on_train_batch_end(self, *args):\n",
    "        \"\"\"After weights updating by the optimisers, clamp the weights\"\"\"\n",
    "        for weight in self.criticC.parameters():\n",
    "            weight.data.clamp_(-0.01, 0.01)\n",
    "        for weight in self.criticB.parameters():\n",
    "            weight.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        celeba_dataset = CelebA(celeba_data_dir, split='train', target_type=[],\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(p=0.2),\n",
    "                                    transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ]))\n",
    "        celeba_dataloader = DataLoader(celeba_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                       collate_fn=custom_collate_fn)\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'train/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.RandomHorizontalFlip(p=0.2),\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return {\n",
    "            'celeba': celeba_dataloader,\n",
    "            'bitmoji': bitmoji_dataloader,\n",
    "        }\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        celeba_dataset = CelebA(celeba_data_dir, split='valid', target_type=[],\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ]))\n",
    "        celeba_dataloader = DataLoader(celeba_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                       collate_fn=custom_collate_fn)\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'val/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return CombinedLoader({\n",
    "            'celeba': celeba_dataloader,\n",
    "            'bitmoji': bitmoji_dataloader,\n",
    "        }, mode='max_size_cycle')\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        celeba_dataset = CelebA(celeba_data_dir, split='test', target_type=[],\n",
    "                                transform=transforms.Compose([\n",
    "                                    transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ]))\n",
    "        celeba_dataloader = DataLoader(celeba_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                       collate_fn=custom_collate_fn)\n",
    "        bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                      transform=transforms.Compose([\n",
    "                                          transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      ]))\n",
    "        bitmoji_dataloader = DataLoader(bitmoji_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                        collate_fn=custom_collate_fn)\n",
    "        return CombinedLoader({\n",
    "            'celeba': celeba_dataloader,\n",
    "            'bitmoji': bitmoji_dataloader,\n",
    "        }, mode='max_size_cycle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7917221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "C2BGenerator (C2BGenerator)              [10, 3, 218, 178]         [10, 3, 128, 128]         --\n",
      "├─Sequential (model): 1-1                [10, 3, 218, 178]         [10, 3, 128, 128]         --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 218, 178]         [10, 6, 218, 178]         168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 218, 178]         [10, 6, 218, 178]         6\n",
      "│    └─BatchNorm2d (2): 2-3              [10, 6, 218, 178]         [10, 6, 218, 178]         12\n",
      "│    └─Conv2d (3): 2-4                   [10, 6, 218, 178]         [10, 8, 215, 176]         584\n",
      "│    └─PReLU (4): 2-5                    [10, 8, 215, 176]         [10, 8, 215, 176]         8\n",
      "│    └─BatchNorm2d (5): 2-6              [10, 8, 215, 176]         [10, 8, 215, 176]         16\n",
      "│    └─Conv2d (6): 2-7                   [10, 8, 215, 176]         [10, 10, 210, 173]        1,930\n",
      "│    └─PReLU (7): 2-8                    [10, 10, 210, 173]        [10, 10, 210, 173]        10\n",
      "│    └─BatchNorm2d (8): 2-9              [10, 10, 210, 173]        [10, 10, 210, 173]        20\n",
      "│    └─Conv2d (9): 2-10                  [10, 10, 210, 173]        [10, 12, 101, 85]         4,812\n",
      "│    └─PReLU (10): 2-11                  [10, 12, 101, 85]         [10, 12, 101, 85]         12\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 12, 101, 85]         [10, 12, 101, 85]         24\n",
      "│    └─Conv2d (12): 2-13                 [10, 12, 101, 85]         [10, 14, 29, 27]          15,134\n",
      "│    └─PReLU (13): 2-14                  [10, 14, 29, 27]          [10, 14, 29, 27]          14\n",
      "│    └─BatchNorm2d (14): 2-15            [10, 14, 29, 27]          [10, 14, 29, 27]          28\n",
      "│    └─ConvTranspose2d (15): 2-16        [10, 14, 29, 27]          [10, 12, 60, 60]          5,388\n",
      "│    └─PReLU (16): 2-17                  [10, 12, 60, 60]          [10, 12, 60, 60]          12\n",
      "│    └─BatchNorm2d (17): 2-18            [10, 12, 60, 60]          [10, 12, 60, 60]          24\n",
      "│    └─ConvTranspose2d (18): 2-19        [10, 12, 60, 60]          [10, 10, 122, 122]        1,930\n",
      "│    └─PReLU (19): 2-20                  [10, 10, 122, 122]        [10, 10, 122, 122]        10\n",
      "│    └─BatchNorm2d (20): 2-21            [10, 10, 122, 122]        [10, 10, 122, 122]        20\n",
      "│    └─ConvTranspose2d (21): 2-22        [10, 10, 122, 122]        [10, 8, 124, 124]         728\n",
      "│    └─PReLU (22): 2-23                  [10, 8, 124, 124]         [10, 8, 124, 124]         8\n",
      "│    └─BatchNorm2d (23): 2-24            [10, 8, 124, 124]         [10, 8, 124, 124]         16\n",
      "│    └─ConvTranspose2d (24): 2-25        [10, 8, 124, 124]         [10, 6, 126, 126]         438\n",
      "│    └─PReLU (25): 2-26                  [10, 6, 126, 126]         [10, 6, 126, 126]         6\n",
      "│    └─BatchNorm2d (26): 2-27            [10, 6, 126, 126]         [10, 6, 126, 126]         12\n",
      "│    └─ConvTranspose2d (27): 2-28        [10, 6, 126, 126]         [10, 3, 128, 128]         165\n",
      "│    └─Hardtanh (28): 2-29               [10, 3, 128, 128]         [10, 3, 128, 128]         --\n",
      "===================================================================================================================\n",
      "Total params: 31,535\n",
      "Trainable params: 31,535\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.21\n",
      "===================================================================================================================\n",
      "Input size (MB): 4.66\n",
      "Forward/backward pass size (MB): 345.48\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 350.27\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "CriticC (CriticC)                        [10, 3, 218, 178]         [10, 1]                   --\n",
      "├─Sequential (model): 1-1                [10, 3, 218, 178]         [10, 1]                   --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 218, 178]         [10, 6, 218, 178]         168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 218, 178]         [10, 6, 218, 178]         6\n",
      "│    └─MaxPool2d (2): 2-3                [10, 6, 218, 178]         [10, 6, 108, 88]          --\n",
      "│    └─BatchNorm2d (3): 2-4              [10, 6, 108, 88]          [10, 6, 108, 88]          12\n",
      "│    └─Conv2d (4): 2-5                   [10, 6, 108, 88]          [10, 9, 106, 86]          495\n",
      "│    └─PReLU (5): 2-6                    [10, 9, 106, 86]          [10, 9, 106, 86]          9\n",
      "│    └─MaxPool2d (6): 2-7                [10, 9, 106, 86]          [10, 9, 52, 42]           --\n",
      "│    └─BatchNorm2d (7): 2-8              [10, 9, 52, 42]           [10, 9, 52, 42]           18\n",
      "│    └─Conv2d (8): 2-9                   [10, 9, 52, 42]           [10, 12, 49, 39]          1,740\n",
      "│    └─PReLU (9): 2-10                   [10, 12, 49, 39]          [10, 12, 49, 39]          12\n",
      "│    └─MaxPool2d (10): 2-11              [10, 12, 49, 39]          [10, 12, 24, 19]          --\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 12, 24, 19]          [10, 12, 24, 19]          24\n",
      "│    └─Conv2d (12): 2-13                 [10, 12, 24, 19]          [10, 15, 11, 8]           2,895\n",
      "│    └─PReLU (13): 2-14                  [10, 15, 11, 8]           [10, 15, 11, 8]           15\n",
      "│    └─MaxPool2d (14): 2-15              [10, 15, 11, 8]           [10, 15, 5, 3]            --\n",
      "│    └─BatchNorm2d (15): 2-16            [10, 15, 5, 3]            [10, 15, 5, 3]            30\n",
      "│    └─Flatten (16): 2-17                [10, 15, 5, 3]            [10, 225]                 --\n",
      "│    └─Linear (17): 2-18                 [10, 225]                 [10, 1]                   226\n",
      "===================================================================================================================\n",
      "Total params: 5,650\n",
      "Trainable params: 5,650\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 146.12\n",
      "===================================================================================================================\n",
      "Input size (MB): 4.66\n",
      "Forward/backward pass size (MB): 60.85\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 65.53\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "B2CGenerator (B2CGenerator)              [10, 3, 128, 128]         [10, 3, 218, 178]         --\n",
      "├─Sequential (model): 1-1                [10, 3, 128, 128]         [10, 3, 218, 178]         --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 128, 128]         [10, 6, 128, 128]         168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 128, 128]         [10, 6, 128, 128]         6\n",
      "│    └─BatchNorm2d (2): 2-3              [10, 6, 128, 128]         [10, 6, 128, 128]         12\n",
      "│    └─Conv2d (3): 2-4                   [10, 6, 128, 128]         [10, 8, 126, 126]         440\n",
      "│    └─PReLU (4): 2-5                    [10, 8, 126, 126]         [10, 8, 126, 126]         8\n",
      "│    └─BatchNorm2d (5): 2-6              [10, 8, 126, 126]         [10, 8, 126, 126]         16\n",
      "│    └─Conv2d (6): 2-7                   [10, 8, 126, 126]         [10, 10, 124, 124]        730\n",
      "│    └─PReLU (7): 2-8                    [10, 10, 124, 124]        [10, 10, 124, 124]        10\n",
      "│    └─BatchNorm2d (8): 2-9              [10, 10, 124, 124]        [10, 10, 124, 124]        20\n",
      "│    └─Conv2d (9): 2-10                  [10, 10, 124, 124]        [10, 12, 61, 61]          1,932\n",
      "│    └─PReLU (10): 2-11                  [10, 12, 61, 61]          [10, 12, 61, 61]          12\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 12, 61, 61]          [10, 12, 61, 61]          24\n",
      "│    └─Conv2d (12): 2-13                 [10, 12, 61, 61]          [10, 14, 29, 27]          5,390\n",
      "│    └─PReLU (13): 2-14                  [10, 14, 29, 27]          [10, 14, 29, 27]          14\n",
      "│    └─BatchNorm2d (14): 2-15            [10, 14, 29, 27]          [10, 14, 29, 27]          28\n",
      "│    └─ConvTranspose2d (15): 2-16        [10, 14, 29, 27]          [10, 12, 100, 85]         15,132\n",
      "│    └─PReLU (16): 2-17                  [10, 12, 100, 85]         [10, 12, 100, 85]         12\n",
      "│    └─BatchNorm2d (17): 2-18            [10, 12, 100, 85]         [10, 12, 100, 85]         24\n",
      "│    └─ConvTranspose2d (18): 2-19        [10, 12, 100, 85]         [10, 10, 208, 172]        4,810\n",
      "│    └─PReLU (19): 2-20                  [10, 10, 208, 172]        [10, 10, 208, 172]        10\n",
      "│    └─BatchNorm2d (20): 2-21            [10, 10, 208, 172]        [10, 10, 208, 172]        20\n",
      "│    └─ConvTranspose2d (21): 2-22        [10, 10, 208, 172]        [10, 8, 213, 175]         1,928\n",
      "│    └─PReLU (22): 2-23                  [10, 8, 213, 175]         [10, 8, 213, 175]         8\n",
      "│    └─BatchNorm2d (23): 2-24            [10, 8, 213, 175]         [10, 8, 213, 175]         16\n",
      "│    └─ConvTranspose2d (24): 2-25        [10, 8, 213, 175]         [10, 6, 216, 177]         582\n",
      "│    └─PReLU (25): 2-26                  [10, 6, 216, 177]         [10, 6, 216, 177]         6\n",
      "│    └─BatchNorm2d (26): 2-27            [10, 6, 216, 177]         [10, 6, 216, 177]         12\n",
      "│    └─ConvTranspose2d (27): 2-28        [10, 6, 216, 177]         [10, 3, 218, 178]         111\n",
      "│    └─Hardtanh (28): 2-29               [10, 3, 218, 178]         [10, 3, 218, 178]         --\n",
      "===================================================================================================================\n",
      "Total params: 31,481\n",
      "Trainable params: 31,481\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 4.32\n",
      "===================================================================================================================\n",
      "Input size (MB): 1.97\n",
      "Forward/backward pass size (MB): 350.60\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 352.69\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "CriticB (CriticB)                        [10, 3, 128, 128]         [10, 1]                   --\n",
      "├─Sequential (model): 1-1                [10, 3, 128, 128]         [10, 1]                   --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 128, 128]         [10, 6, 128, 128]         168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 128, 128]         [10, 6, 128, 128]         6\n",
      "│    └─MaxPool2d (2): 2-3                [10, 6, 128, 128]         [10, 6, 63, 63]           --\n",
      "│    └─BatchNorm2d (3): 2-4              [10, 6, 63, 63]           [10, 6, 63, 63]           12\n",
      "│    └─Conv2d (4): 2-5                   [10, 6, 63, 63]           [10, 9, 61, 61]           495\n",
      "│    └─PReLU (5): 2-6                    [10, 9, 61, 61]           [10, 9, 61, 61]           9\n",
      "│    └─MaxPool2d (6): 2-7                [10, 9, 61, 61]           [10, 9, 30, 30]           --\n",
      "│    └─BatchNorm2d (7): 2-8              [10, 9, 30, 30]           [10, 9, 30, 30]           18\n",
      "│    └─Conv2d (8): 2-9                   [10, 9, 30, 30]           [10, 12, 27, 27]          1,740\n",
      "│    └─PReLU (9): 2-10                   [10, 12, 27, 27]          [10, 12, 27, 27]          12\n",
      "│    └─MaxPool2d (10): 2-11              [10, 12, 27, 27]          [10, 12, 13, 13]          --\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 12, 13, 13]          [10, 12, 13, 13]          24\n",
      "│    └─Conv2d (12): 2-13                 [10, 12, 13, 13]          [10, 15, 5, 5]            2,895\n",
      "│    └─PReLU (13): 2-14                  [10, 15, 5, 5]            [10, 15, 5, 5]            15\n",
      "│    └─MaxPool2d (14): 2-15              [10, 15, 5, 5]            [10, 15, 2, 2]            --\n",
      "│    └─BatchNorm2d (15): 2-16            [10, 15, 2, 2]            [10, 15, 2, 2]            30\n",
      "│    └─Flatten (16): 2-17                [10, 15, 2, 2]            [10, 60]                  --\n",
      "│    └─Linear (17): 2-18                 [10, 60]                  [10, 1]                   61\n",
      "===================================================================================================================\n",
      "Total params: 5,485\n",
      "Trainable params: 5,485\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 59.35\n",
      "===================================================================================================================\n",
      "Input size (MB): 1.97\n",
      "Forward/backward pass size (MB): 25.27\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 27.25\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary_kwargs = dict(dtypes=[torch.float], depth=3, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                      row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "ns = 10\n",
    "\n",
    "celeba = torch.randn((ns, 3, 218, 178), dtype=torch.float)\n",
    "summary_string = str(summary(model=C2BGenerator(), input_data=celeba, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "summary_string = str(summary(model=CriticC(), input_data=celeba, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "bitmoji = torch.randn((ns, 3, 128, 128), dtype=torch.float)\n",
    "summary_string = str(summary(model=B2CGenerator(), input_data=bitmoji, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "summary_string = str(summary(model=CriticB(), input_data=bitmoji, **summary_kwargs))\n",
    "print(summary_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a8a7a",
   "metadata": {},
   "source": [
    "# Cycle WGAN for SVHN - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123475c6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef34add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2MGenerator(Module):\n",
    "    \"\"\"\n",
    "    Take SVHN image [-1, 1] and generate \"fake\" MNIST image [-1, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(S2MGenerator, self).__init__()\n",
    "        self.model = Sequential(\n",
    "            # Downsampling part\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            Conv2d(in_channels=8, out_channels=10, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            Conv2d(in_channels=10, out_channels=12, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            # Upsampling part\n",
    "            ConvTranspose2d(in_channels=12, out_channels=10, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            ConvTranspose2d(in_channels=10, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            ConvTranspose2d(in_channels=8, out_channels=6, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            ConvTranspose2d(in_channels=6, out_channels=5, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=5, init=0.25),\n",
    "            BatchNorm2d(num_features=5),\n",
    "\n",
    "            ConvTranspose2d(in_channels=5, out_channels=3, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=3, init=0.25),\n",
    "            BatchNorm2d(num_features=3),\n",
    "\n",
    "            ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            Hardtanh(min_val=-1, max_val=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 27, 3):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['27'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class M2SGenerator(Module):\n",
    "    \"\"\"\n",
    "    Take MNIST image [-1, 1] and generate \"fake\" SVHN image [-1, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(M2SGenerator, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            # Downsampling part\n",
    "            Conv2d(in_channels=1, out_channels=3, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=3, init=0.25),\n",
    "            BatchNorm2d(num_features=3),\n",
    "\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            Conv2d(in_channels=10, out_channels=12, kernel_size=(4, 4), stride=(2, 2)),\n",
    "            PReLU(num_parameters=12, init=0.25),\n",
    "            BatchNorm2d(num_features=12),\n",
    "\n",
    "            # Upsampling part\n",
    "            ConvTranspose2d(in_channels=12, out_channels=10, kernel_size=(4, 4), stride=(2, 2), output_padding=1),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            ConvTranspose2d(in_channels=10, out_channels=10, kernel_size=(4, 4), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            ConvTranspose2d(in_channels=10, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            ConvTranspose2d(in_channels=8, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            ConvTranspose2d(in_channels=6, out_channels=3, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            Hardtanh(min_val=-1, max_val=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 27, 3):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['27'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CriticM(Module):\n",
    "    \"\"\"\n",
    "    Critic for MNIST images - Checks if the mnist image passed is from mnist \"real\" data distribution or from \"fake\" S2M generator\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CriticM, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=1, out_channels=3, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=3, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=3),\n",
    "\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=9, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=9, init=0.25),\n",
    "            BatchNorm2d(num_features=9),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=81, out_features=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 9, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['12'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CriticS(Module):\n",
    "    \"\"\"\n",
    "    Critic for SVHN images - Checks if the svhn image passed is from svhn \"real\" data distribution or from \"fake\" M2S generator\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CriticS, self).__init__()\n",
    "\n",
    "        self.model = Sequential(\n",
    "            Conv2d(in_channels=3, out_channels=6, kernel_size=(3, 3), stride=(1, 1), padding='same'),\n",
    "            PReLU(num_parameters=6, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=6),\n",
    "\n",
    "            Conv2d(in_channels=6, out_channels=8, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=8, init=0.25),\n",
    "            MaxPool2d(kernel_size=(3, 3), stride=(2, 2)),\n",
    "            BatchNorm2d(num_features=8),\n",
    "\n",
    "            Conv2d(in_channels=8, out_channels=10, kernel_size=(3, 3), stride=(1, 1)),\n",
    "            PReLU(num_parameters=10, init=0.25),\n",
    "            BatchNorm2d(num_features=10),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Linear(in_features=160, out_features=1),\n",
    "        )\n",
    "\n",
    "    def initialise(self):\n",
    "        for i in range(0, 9, 4):\n",
    "            init.kaiming_normal_(self.model._modules[str(i)].weight, a=0.25, nonlinearity='leaky_relu')\n",
    "        init.xavier_normal_(self.model._modules['12'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class SMCycleWGAN(LightningModule):\n",
    "\n",
    "    def __init__(self, ncritic, ngen, bs, cycle_weight):\n",
    "        super(SMCycleWGAN, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.ncritic = ncritic\n",
    "        self.ngen = ngen\n",
    "        self.bs = bs\n",
    "        self.cycle_weight = cycle_weight\n",
    "\n",
    "        # SVHN to MNIST\n",
    "        self.genS2M = S2MGenerator()\n",
    "        self.criticM = CriticM()\n",
    "\n",
    "        # MNIST to SVHN\n",
    "        self.genM2S = M2SGenerator()\n",
    "        self.criticS = CriticS()\n",
    "\n",
    "        # Initialisations\n",
    "        self.genS2M.initialise()\n",
    "        self.criticM.initialise()\n",
    "        self.genM2S.initialise()\n",
    "        self.criticS.initialise()\n",
    "\n",
    "        # CycleGAN authors use image pool to update the discriminator. That was required because GAN training (on the\n",
    "        # usual objective) was unstable. We are using WGAN and hopefully won't get into such issues. Hence, skipping\n",
    "        # keeping the pool of images\n",
    "\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, real_svhns, real_mnists):\n",
    "        real_mnist_scores = self.criticM(real_mnists)\n",
    "        real_svhn_scores = self.criticS(real_svhns)\n",
    "        fake_mnists = self.genS2M(real_svhns)\n",
    "        fake_svhns = self.genM2S(real_mnists)\n",
    "        return real_svhn_scores, real_mnist_scores, fake_svhns, fake_mnists\n",
    "\n",
    "    def _critic_losses(self, real_svhns, real_mnists, btype):\n",
    "        # WGAN: Critic gets updated from the fake and real data\n",
    "        # CycleGAN: Need to do this for both critics!\n",
    "\n",
    "        # MNIST Critic\n",
    "        real_mnists_score = self.criticM(real_mnists).mean()\n",
    "        fake_mnists = self.genS2M(real_svhns)\n",
    "        fake_mnists_score = self.criticM(fake_mnists).mean()\n",
    "        criticM_loss = fake_mnists_score - real_mnists_score  # minimise this!\n",
    "\n",
    "        # SVHN Critic\n",
    "        real_svhns_score = self.criticS(real_svhns).mean()\n",
    "        fake_svhns = self.genM2S(real_mnists)\n",
    "        fake_svhns_score = self.criticS(fake_svhns).mean()\n",
    "        criticS_loss = fake_svhns_score - real_svhns_score\n",
    "\n",
    "        not_training = btype != 'train'\n",
    "        self.log(f'{btype}/criticM_loss', criticM_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/criticS_loss', criticS_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        return criticM_loss, criticS_loss\n",
    "\n",
    "    def _generator_losses(self, real_svhns, real_mnists, btype):\n",
    "        # WGAN: Generator gets updates from the fake data\n",
    "        # CycleGAN: Do this for both generators and additionally put cycle consistency loss\n",
    "\n",
    "        # SVHN to MNIST\n",
    "        fake_mnists = self.genS2M(real_svhns)\n",
    "        fake_mnists_score = self.criticM(fake_mnists).mean()\n",
    "        genS2M_loss = -fake_mnists_score  # minimise this!\n",
    "\n",
    "        # MNIST to SVHN\n",
    "        fake_svhns = self.genM2S(real_mnists)\n",
    "        fake_svhns_score = self.criticS(fake_svhns).mean()\n",
    "        genM2S_loss = -fake_svhns_score\n",
    "\n",
    "        # Cycle Consistency\n",
    "        # Side Note: *Ideally* L1 norm should be added across dimensions and mean-ed across samples. In their\n",
    "        # implementation, authors have mean-ed across dimensions too, keeping same implementation as them\n",
    "        svhn_identity_loss = L1Loss()(real_svhns, self.genM2S(fake_mnists))\n",
    "        mnist_identity_loss = L1Loss()(real_mnists, self.genS2M(fake_svhns))\n",
    "        cycle_loss = self.cycle_weight * (svhn_identity_loss + mnist_identity_loss)\n",
    "\n",
    "        not_training = btype != 'train'\n",
    "        self.log(f'{btype}/genS2M_loss', genS2M_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/genM2S_loss', genM2S_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/cycle_loss',  cycle_loss,  on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/svhn_identity_loss',  svhn_identity_loss,  on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "        self.log(f'{btype}/mnist_identity_loss', mnist_identity_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=not_training)\n",
    "\n",
    "        return genS2M_loss, genM2S_loss, cycle_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real_svhns, real_mnists = batch['svhn'][0], batch['mnist'][0]\n",
    "\n",
    "        if optimizer_idx == 1:  # Critic optimizer - only update Critic weights\n",
    "            criticM_loss, criticS_loss = self._critic_losses(real_svhns, real_mnists, 'train')\n",
    "            # CycleGAN authors divide this loss by 2 to slow down the rate of critic learning. Here, as the loss is\n",
    "            # wasserstein loss, I believe it may not be required\n",
    "            return criticM_loss + criticS_loss\n",
    "\n",
    "        if optimizer_idx == 0:  # Generator optimizer - only update Generator weights\n",
    "            genS2M_loss, genM2S_loss, cycle_loss = self._generator_losses(real_svhns, real_mnists, 'train')\n",
    "            return genS2M_loss + genM2S_loss + cycle_loss\n",
    "\n",
    "        # Is there a way to consolidate the losses and return one per epoch?\n",
    "        raise Exception(f'Unknown optimizer index: {optimizer_idx}')\n",
    "\n",
    "    def _shared_eval(self, batch, btype):\n",
    "        real_svhns, real_mnists = batch['svhn'][0], batch['mnist'][0]\n",
    "        criticM_loss, criticS_loss = self._critic_losses(real_svhns, real_mnists, btype)\n",
    "        genS2M_loss, genM2S_loss, cycle_loss = self._generator_losses(real_svhns, real_mnists, btype)\n",
    "        total_loss = criticM_loss + criticS_loss + genS2M_loss + genM2S_loss + cycle_loss\n",
    "        self.log(f'{btype}/loss', total_loss, on_step=False, on_epoch=True, reduce_fx=torch.mean, sync_dist=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, 'test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Using the strategy from WGAN paper instead of CycleGAN paper!\"\"\"\n",
    "        generator_opt = RMSprop(params=itertools.chain(self.genS2M.parameters(), self.genM2S.parameters()), lr=0.00005)\n",
    "        critic_opt = RMSprop(params=itertools.chain(self.criticS.parameters(), self.criticM.parameters()), lr=0.00005)\n",
    "        return (\n",
    "            {\"optimizer\": generator_opt, \"frequency\": self.ngen},\n",
    "            {\"optimizer\": critic_opt, \"frequency\": self.ncritic},\n",
    "        )\n",
    "\n",
    "    def on_train_batch_end(self, *args):\n",
    "        \"\"\"After weights updating by the optimisers, clamp the weights\"\"\"\n",
    "        for weight in self.criticS.parameters():\n",
    "            weight.data.clamp_(-0.01, 0.01)\n",
    "        for weight in self.criticM.parameters():\n",
    "            weight.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        svhn_dataset = SVHN(svhn_data_dir, split='train',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "        svhn_dataloader = DataLoader(svhn_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                     collate_fn=custom_collate_fn)\n",
    "        mnist_dataset = MNIST(mnist_data_dir, train=True,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                  transforms.Normalize((0.5, ), (0.5, )),\n",
    "                              ]))\n",
    "        mnist_dataloader = DataLoader(mnist_dataset, self.bs, shuffle=True, num_workers=0,\n",
    "                                      collate_fn=custom_collate_fn)\n",
    "        return {\n",
    "            'svhn': svhn_dataloader,\n",
    "            'mnist': mnist_dataloader,\n",
    "        }\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        svhn_dataset = SVHN(svhn_data_dir, split='test',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "        svhn_dataloader = DataLoader(svhn_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                     collate_fn=custom_collate_fn)\n",
    "        mnist_dataset = MNIST(mnist_data_dir, train=False,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                  transforms.Normalize((0.5, ), (0.5, )),\n",
    "                              ]))\n",
    "        mnist_dataloader = DataLoader(mnist_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                      collate_fn=custom_collate_fn)\n",
    "        return CombinedLoader({\n",
    "            'svhn': svhn_dataloader,\n",
    "            'mnist': mnist_dataloader,\n",
    "        }, mode='max_size_cycle')\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        svhn_dataset = SVHN(svhn_data_dir, split='test',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "        svhn_dataloader = DataLoader(svhn_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                     collate_fn=custom_collate_fn)\n",
    "        mnist_dataset = MNIST(mnist_data_dir, train=False,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                  transforms.Normalize((0.5, ), (0.5, )),\n",
    "                              ]))\n",
    "        mnist_dataloader = DataLoader(mnist_dataset, self.bs, shuffle=False, num_workers=0,\n",
    "                                      collate_fn=custom_collate_fn)\n",
    "        return CombinedLoader({\n",
    "            'svhn': svhn_dataloader,\n",
    "            'mnist': mnist_dataloader,\n",
    "        }, mode='max_size_cycle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e681cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "S2MGenerator (S2MGenerator)              [10, 3, 32, 32]           [10, 1, 28, 28]           --\n",
      "├─Sequential (model): 1-1                [10, 3, 32, 32]           [10, 1, 28, 28]           --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 32, 32]           [10, 6, 32, 32]           168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 32, 32]           [10, 6, 32, 32]           6\n",
      "│    └─BatchNorm2d (2): 2-3              [10, 6, 32, 32]           [10, 6, 32, 32]           12\n",
      "│    └─Conv2d (3): 2-4                   [10, 6, 32, 32]           [10, 8, 30, 30]           440\n",
      "│    └─PReLU (4): 2-5                    [10, 8, 30, 30]           [10, 8, 30, 30]           8\n",
      "│    └─BatchNorm2d (5): 2-6              [10, 8, 30, 30]           [10, 8, 30, 30]           16\n",
      "│    └─Conv2d (6): 2-7                   [10, 8, 30, 30]           [10, 10, 27, 27]          1,290\n",
      "│    └─PReLU (7): 2-8                    [10, 10, 27, 27]          [10, 10, 27, 27]          10\n",
      "│    └─BatchNorm2d (8): 2-9              [10, 10, 27, 27]          [10, 10, 27, 27]          20\n",
      "│    └─Conv2d (9): 2-10                  [10, 10, 27, 27]          [10, 12, 12, 12]          1,932\n",
      "│    └─PReLU (10): 2-11                  [10, 12, 12, 12]          [10, 12, 12, 12]          12\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 12, 12, 12]          [10, 12, 12, 12]          24\n",
      "│    └─ConvTranspose2d (12): 2-13        [10, 12, 12, 12]          [10, 10, 14, 14]          1,090\n",
      "│    └─PReLU (13): 2-14                  [10, 10, 14, 14]          [10, 10, 14, 14]          10\n",
      "│    └─BatchNorm2d (14): 2-15            [10, 10, 14, 14]          [10, 10, 14, 14]          20\n",
      "│    └─ConvTranspose2d (15): 2-16        [10, 10, 14, 14]          [10, 8, 16, 16]           728\n",
      "│    └─PReLU (16): 2-17                  [10, 8, 16, 16]           [10, 8, 16, 16]           8\n",
      "│    └─BatchNorm2d (17): 2-18            [10, 8, 16, 16]           [10, 8, 16, 16]           16\n",
      "│    └─ConvTranspose2d (18): 2-19        [10, 8, 16, 16]           [10, 6, 19, 19]           774\n",
      "│    └─PReLU (19): 2-20                  [10, 6, 19, 19]           [10, 6, 19, 19]           6\n",
      "│    └─BatchNorm2d (20): 2-21            [10, 6, 19, 19]           [10, 6, 19, 19]           12\n",
      "│    └─ConvTranspose2d (21): 2-22        [10, 6, 19, 19]           [10, 5, 22, 22]           485\n",
      "│    └─PReLU (22): 2-23                  [10, 5, 22, 22]           [10, 5, 22, 22]           5\n",
      "│    └─BatchNorm2d (23): 2-24            [10, 5, 22, 22]           [10, 5, 22, 22]           10\n",
      "│    └─ConvTranspose2d (24): 2-25        [10, 5, 22, 22]           [10, 3, 25, 25]           243\n",
      "│    └─PReLU (25): 2-26                  [10, 3, 25, 25]           [10, 3, 25, 25]           3\n",
      "│    └─BatchNorm2d (26): 2-27            [10, 3, 25, 25]           [10, 3, 25, 25]           6\n",
      "│    └─ConvTranspose2d (27): 2-28        [10, 3, 25, 25]           [10, 1, 28, 28]           49\n",
      "│    └─Hardtanh (28): 2-29               [10, 1, 28, 28]           [10, 1, 28, 28]           --\n",
      "===================================================================================================================\n",
      "Total params: 7,403\n",
      "Trainable params: 7,403\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 28.91\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 7.94\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 8.09\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "CriticS (CriticS)                        [10, 3, 32, 32]           [10, 1]                   --\n",
      "├─Sequential (model): 1-1                [10, 3, 32, 32]           [10, 1]                   --\n",
      "│    └─Conv2d (0): 2-1                   [10, 3, 32, 32]           [10, 6, 32, 32]           168\n",
      "│    └─PReLU (1): 2-2                    [10, 6, 32, 32]           [10, 6, 32, 32]           6\n",
      "│    └─MaxPool2d (2): 2-3                [10, 6, 32, 32]           [10, 6, 15, 15]           --\n",
      "│    └─BatchNorm2d (3): 2-4              [10, 6, 15, 15]           [10, 6, 15, 15]           12\n",
      "│    └─Conv2d (4): 2-5                   [10, 6, 15, 15]           [10, 8, 13, 13]           440\n",
      "│    └─PReLU (5): 2-6                    [10, 8, 13, 13]           [10, 8, 13, 13]           8\n",
      "│    └─MaxPool2d (6): 2-7                [10, 8, 13, 13]           [10, 8, 6, 6]             --\n",
      "│    └─BatchNorm2d (7): 2-8              [10, 8, 6, 6]             [10, 8, 6, 6]             16\n",
      "│    └─Conv2d (8): 2-9                   [10, 8, 6, 6]             [10, 10, 4, 4]            730\n",
      "│    └─PReLU (9): 2-10                   [10, 10, 4, 4]            [10, 10, 4, 4]            10\n",
      "│    └─BatchNorm2d (10): 2-11            [10, 10, 4, 4]            [10, 10, 4, 4]            20\n",
      "│    └─Flatten (11): 2-12                [10, 10, 4, 4]            [10, 160]                 --\n",
      "│    └─Linear (12): 2-13                 [10, 160]                 [10, 1]                   161\n",
      "===================================================================================================================\n",
      "Total params: 1,571\n",
      "Trainable params: 1,571\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 2.58\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 1.37\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 1.50\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "M2SGenerator (M2SGenerator)              [10, 1, 28, 28]           [10, 3, 32, 32]           --\n",
      "├─Sequential (model): 1-1                [10, 1, 28, 28]           [10, 3, 32, 32]           --\n",
      "│    └─Conv2d (0): 2-1                   [10, 1, 28, 28]           [10, 3, 28, 28]           30\n",
      "│    └─PReLU (1): 2-2                    [10, 3, 28, 28]           [10, 3, 28, 28]           3\n",
      "│    └─BatchNorm2d (2): 2-3              [10, 3, 28, 28]           [10, 3, 28, 28]           6\n",
      "│    └─Conv2d (3): 2-4                   [10, 3, 28, 28]           [10, 6, 26, 26]           168\n",
      "│    └─PReLU (4): 2-5                    [10, 6, 26, 26]           [10, 6, 26, 26]           6\n",
      "│    └─BatchNorm2d (5): 2-6              [10, 6, 26, 26]           [10, 6, 26, 26]           12\n",
      "│    └─Conv2d (6): 2-7                   [10, 6, 26, 26]           [10, 8, 24, 24]           440\n",
      "│    └─PReLU (7): 2-8                    [10, 8, 24, 24]           [10, 8, 24, 24]           8\n",
      "│    └─BatchNorm2d (8): 2-9              [10, 8, 24, 24]           [10, 8, 24, 24]           16\n",
      "│    └─Conv2d (9): 2-10                  [10, 8, 24, 24]           [10, 10, 22, 22]          730\n",
      "│    └─PReLU (10): 2-11                  [10, 10, 22, 22]          [10, 10, 22, 22]          10\n",
      "│    └─BatchNorm2d (11): 2-12            [10, 10, 22, 22]          [10, 10, 22, 22]          20\n",
      "│    └─Conv2d (12): 2-13                 [10, 10, 22, 22]          [10, 12, 10, 10]          1,932\n",
      "│    └─PReLU (13): 2-14                  [10, 12, 10, 10]          [10, 12, 10, 10]          12\n",
      "│    └─BatchNorm2d (14): 2-15            [10, 12, 10, 10]          [10, 12, 10, 10]          24\n",
      "│    └─ConvTranspose2d (15): 2-16        [10, 12, 10, 10]          [10, 10, 23, 23]          1,930\n",
      "│    └─PReLU (16): 2-17                  [10, 10, 23, 23]          [10, 10, 23, 23]          10\n",
      "│    └─BatchNorm2d (17): 2-18            [10, 10, 23, 23]          [10, 10, 23, 23]          20\n",
      "│    └─ConvTranspose2d (18): 2-19        [10, 10, 23, 23]          [10, 10, 26, 26]          1,610\n",
      "│    └─PReLU (19): 2-20                  [10, 10, 26, 26]          [10, 10, 26, 26]          10\n",
      "│    └─BatchNorm2d (20): 2-21            [10, 10, 26, 26]          [10, 10, 26, 26]          20\n",
      "│    └─ConvTranspose2d (21): 2-22        [10, 10, 26, 26]          [10, 8, 28, 28]           728\n",
      "│    └─PReLU (22): 2-23                  [10, 8, 28, 28]           [10, 8, 28, 28]           8\n",
      "│    └─BatchNorm2d (23): 2-24            [10, 8, 28, 28]           [10, 8, 28, 28]           16\n",
      "│    └─ConvTranspose2d (24): 2-25        [10, 8, 28, 28]           [10, 6, 30, 30]           438\n",
      "│    └─PReLU (25): 2-26                  [10, 6, 30, 30]           [10, 6, 30, 30]           6\n",
      "│    └─BatchNorm2d (26): 2-27            [10, 6, 30, 30]           [10, 6, 30, 30]           12\n",
      "│    └─ConvTranspose2d (27): 2-28        [10, 6, 30, 30]           [10, 3, 32, 32]           165\n",
      "│    └─Hardtanh (28): 2-29               [10, 3, 32, 32]           [10, 3, 32, 32]           --\n",
      "===================================================================================================================\n",
      "Total params: 8,390\n",
      "Trainable params: 8,390\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 41.81\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 10.03\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 10.10\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "CriticM (CriticM)                        [10, 1, 28, 28]           [10, 1]                   --\n",
      "├─Sequential (model): 1-1                [10, 1, 28, 28]           [10, 1]                   --\n",
      "│    └─Conv2d (0): 2-1                   [10, 1, 28, 28]           [10, 3, 28, 28]           30\n",
      "│    └─PReLU (1): 2-2                    [10, 3, 28, 28]           [10, 3, 28, 28]           3\n",
      "│    └─MaxPool2d (2): 2-3                [10, 3, 28, 28]           [10, 3, 13, 13]           --\n",
      "│    └─BatchNorm2d (3): 2-4              [10, 3, 13, 13]           [10, 3, 13, 13]           6\n",
      "│    └─Conv2d (4): 2-5                   [10, 3, 13, 13]           [10, 6, 11, 11]           168\n",
      "│    └─PReLU (5): 2-6                    [10, 6, 11, 11]           [10, 6, 11, 11]           6\n",
      "│    └─MaxPool2d (6): 2-7                [10, 6, 11, 11]           [10, 6, 5, 5]             --\n",
      "│    └─BatchNorm2d (7): 2-8              [10, 6, 5, 5]             [10, 6, 5, 5]             12\n",
      "│    └─Conv2d (8): 2-9                   [10, 6, 5, 5]             [10, 9, 3, 3]             495\n",
      "│    └─PReLU (9): 2-10                   [10, 9, 3, 3]             [10, 9, 3, 3]             9\n",
      "│    └─BatchNorm2d (10): 2-11            [10, 9, 3, 3]             [10, 9, 3, 3]             18\n",
      "│    └─Flatten (11): 2-12                [10, 9, 3, 3]             [10, 81]                  --\n",
      "│    └─Linear (12): 2-13                 [10, 81]                  [10, 1]                   82\n",
      "===================================================================================================================\n",
      "Total params: 829\n",
      "Trainable params: 829\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.48\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 0.56\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.60\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "summary_kwargs = dict(dtypes=[torch.float], depth=3, col_names=['input_size', 'output_size', 'num_params'],\n",
    "                          row_settings=['depth', 'var_names'], verbose=0, device=torch.device('cpu'))\n",
    "ns = 10\n",
    "\n",
    "svhn = torch.randn((ns, 3, 32, 32), dtype=torch.float)\n",
    "summary_string = str(summary(model=S2MGenerator(), input_data=svhn, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "summary_string = str(summary(model=CriticS(), input_data=svhn, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "mnist = torch.randn((ns, 1, 28, 28), dtype=torch.float)\n",
    "summary_string = str(summary(model=M2SGenerator(), input_data=mnist, **summary_kwargs))\n",
    "print(summary_string)\n",
    "\n",
    "summary_string = str(summary(model=CriticM(), input_data=mnist, **summary_kwargs))\n",
    "print(summary_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537bc3e",
   "metadata": {},
   "source": [
    "# Common Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb034f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(max_epochs: int,\n",
    "                   tags: list[str], gpu_num: list[int],\n",
    "                   model_class, model_kwargs: dict,\n",
    "                   loss_desc: str, input_shape: list[tuple]):\n",
    "    seed_everything(0, workers=True)\n",
    "\n",
    "    folder_name = datetime.utcnow().isoformat(sep=\"T\", timespec=\"microseconds\")\n",
    "    results_dir = project_dir + f'gan/results/run_{folder_name}/'\n",
    "    os.makedirs(results_dir, exist_ok=False)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val/loss', mode='min', dirpath=results_dir,\n",
    "                                          save_last=True, save_top_k=10, auto_insert_metric_name=False,\n",
    "                                          filename='epoch={epoch}-val_loss={val/loss:.4f}')\n",
    "\n",
    "    if use_gpu:\n",
    "        trainer_kwargs = dict(accelerator=\"gpu\", devices=gpu_num)\n",
    "    else:\n",
    "        trainer_kwargs = dict()\n",
    "\n",
    "    tf_logger = TensorBoardLogger(save_dir=results_dir, version=f'tf_logs',\n",
    "                                  default_hp_metric=False)\n",
    "\n",
    "    model = model_class(**model_kwargs)\n",
    "\n",
    "    trainer = Trainer(default_root_dir=results_dir, max_epochs=max_epochs,\n",
    "                      callbacks=[checkpoint_callback], logger=[tf_logger],\n",
    "                      log_every_n_steps=1, num_sanity_val_steps=0, multiple_trainloader_mode='max_size_cycle',\n",
    "                      limit_train_batches=5, limit_val_batches=1, limit_test_batches=1,\n",
    "                      deterministic=True, **trainer_kwargs)\n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "\n",
    "    summary_string = str(summary(model=model, input_size=[(10, *input_shape[0]), (10, *input_shape[1])],\n",
    "                                 dtypes=[torch.float, torch.float], depth=3, verbose=0,\n",
    "                                 col_names=['input_size', 'output_size', 'num_params'],\n",
    "                                 row_settings=['depth', 'var_names'], device=torch.device('cpu'))) + '\\n' + loss_desc\n",
    "    with open(results_dir + 'model_desc.md', 'w') as f:\n",
    "        f.write(summary_string)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bbc51",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31251227",
   "metadata": {},
   "source": [
    "## CelebA - Bitmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88b5007",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | genC2B  | C2BGenerator | 31.5 K\n",
      "1 | criticB | CriticB      | 5.5 K \n",
      "2 | genB2C  | B2CGenerator | 31.5 K\n",
      "3 | criticC | CriticC      | 5.7 K \n",
      "-----------------------------------------\n",
      "74.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "74.2 K    Total params\n",
      "0.297     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01645684242248535,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2229f26f467b426eb0aee90861e58869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00870823860168457,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010818958282470703,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009840011596679688,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba12bca2192b497eb0992d379b300686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric               DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "test/bitmoji_identity_loss    0.8739818930625916\n",
      "test/celeba_identity_loss     0.7569977045059204\n",
      "    test/criticB_loss                0.0\n",
      "    test/criticC_loss                0.0\n",
      "     test/cycle_loss          1.6309795379638672\n",
      "     test/genB2C_loss        0.009965265169739723\n",
      "     test/genC2B_loss       -0.010036039166152477\n",
      "        test/loss             1.630908727645874\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "train_and_test(max_epochs=2, tags=[], gpu_num=[],\n",
    "               model_class=CBCycleWGAN, model_kwargs=dict(ncritic=2, ngen=1, cycle_weight=1, bs=4),\n",
    "               loss_desc='General loss', input_shape=[(3, 218, 178), (3, 128, 128)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294f667",
   "metadata": {},
   "source": [
    "## SVHN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eec75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | genS2M  | S2MGenerator | 7.4 K \n",
      "1 | criticM | CriticM      | 829   \n",
      "2 | genM2S  | M2SGenerator | 8.4 K \n",
      "3 | criticS | CriticS      | 1.6 K \n",
      "-----------------------------------------\n",
      "18.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.2 K    Total params\n",
      "0.073     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01871204376220703,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Training",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb53c9e8f71402a90213be0dd8cb8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008262872695922852,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00800776481628418,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Validation",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008188009262084961,
       "initial": 0,
       "n": 0,
       "ncols": 155,
       "nrows": 17,
       "postfix": null,
       "prefix": "Testing",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174e2ff599ef46648dac0cd804cd66ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    test/criticM_loss               0.0\n",
      "    test/criticS_loss               0.0\n",
      "     test/cycle_loss        15.491276741027832\n",
      "    test/genM2S_loss        0.01000344567000866\n",
      "    test/genS2M_loss       -0.01000091340392828\n",
      "        test/loss           15.491279602050781\n",
      "test/mnist_identity_loss    1.1419328451156616\n",
      " test/svhn_identity_loss    0.4071948528289795\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "train_and_test(max_epochs=2, tags=[], gpu_num=[],\n",
    "                   model_class=SMCycleWGAN, model_kwargs=dict(ncritic=2, ngen=1, cycle_weight=10, bs=4),\n",
    "                   loss_desc='General loss', input_shape=[(3, 32, 32), (1, 28, 28)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe06de4",
   "metadata": {},
   "source": [
    "# Plots & Analysis\n",
    "\n",
    "See GitHub code for examples of usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72974760",
   "metadata": {},
   "source": [
    "## CelebA - Bitmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a392d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side(title, reals, gens, fname):\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01, left=0, bottom=0, right=1, top=0.95)\n",
    "    axes = axes.flat\n",
    "\n",
    "    for i in range(reals.shape[0]):\n",
    "        target_idx = 2 * i\n",
    "        ax = axes[target_idx]\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(reals[i])\n",
    "\n",
    "        pred_idx = target_idx + 1\n",
    "        ax = axes[pred_idx]\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(gens[i])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.savefig(project_dir + f'gan/celeba_bitmoji/img_results/{fname}')\n",
    "\n",
    "\n",
    "def convert_to_image(ndarray):  # -1 to 1\n",
    "    ndarray = ndarray * 0.5 + 0.5  # 0 to 1\n",
    "    ndarray *= 255  # 0 to 255\n",
    "    ndarray = numpy.round(ndarray, decimals=0)  # rounded off\n",
    "    return ndarray.astype(int)\n",
    "\n",
    "\n",
    "def see_some_translations(model, celeba, bitmoji, model_type):\n",
    "    gen_bitmoji = model.genC2B(celeba).detach().numpy()\n",
    "    gen_celeba = model.genB2C(bitmoji).detach().numpy()\n",
    "\n",
    "    celeba = convert_to_image(numpy.transpose(celeba.numpy(), (0, 2, 3, 1)))\n",
    "    bitmoji = convert_to_image(numpy.transpose(bitmoji.numpy(), (0, 2, 3, 1)))\n",
    "    gen_bitmoji = convert_to_image(numpy.transpose(gen_bitmoji, (0, 2, 3, 1)))\n",
    "    gen_celeba = convert_to_image(numpy.transpose(gen_celeba, (0, 2, 3, 1)))\n",
    "\n",
    "    plot_side_by_side(f'CelebA to Bitmoji - NCritic = {model.ncritic}, NGen = {model.ngen}, Cycle Weight = {model.cycle_weight} - {model_type}',\n",
    "                      celeba, gen_bitmoji, f'gan_trans_ncritic={model.ncritic}_ngen={model.ngen}_cycleweight={model.cycle_weight}_{model_type}_c2b')\n",
    "    plot_side_by_side(f'Bitmoji to CelebA - NCritic = {model.ncritic}, NGen = {model.ngen}, Cycle Weight = {model.cycle_weight} - {model_type}',\n",
    "                      bitmoji, gen_celeba, f'gan_trans_ncritic={model.ncritic}_ngen={model.ngen}_cycleweight={model.cycle_weight}_{model_type}_b2c')\n",
    "\n",
    "\n",
    "def get_data(num_images):\n",
    "    celeba_dataset = CelebA(celeba_data_dir, split='test', target_type=[],\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "    celeba_dataloader = DataLoader(celeba_dataset, num_images, shuffle=True, num_workers=num_cpus,\n",
    "                                   collate_fn=custom_collate_fn)\n",
    "    celeba = next(iter(celeba_dataloader))\n",
    "\n",
    "    bitmoji_dataset = ImageFolder(bitmoji_data_dir + 'test/',\n",
    "                                  transform=transforms.Compose([\n",
    "                                      transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                  ]))\n",
    "    bitmoji_dataloader = DataLoader(bitmoji_dataset, num_images, shuffle=True, num_workers=num_cpus,\n",
    "                                    collate_fn=custom_collate_fn)\n",
    "    bitmoji = next(iter(bitmoji_dataloader))\n",
    "    return celeba[0], bitmoji[0]\n",
    "\n",
    "\n",
    "def give_best_fname(direc):\n",
    "    data = []\n",
    "    for fname in glob(direc + 'epoch*.ckpt'):\n",
    "        val_loss = float(fname.replace(direc, '').split('=')[2].replace('.ckpt', ''))\n",
    "        data.append({'fname': fname, 'val_loss': val_loss})\n",
    "    df = pandas.DataFrame(data)\n",
    "    min_idx = df.val_loss.idxmin()\n",
    "    best_fname = df.fname[min_idx]\n",
    "    return best_fname\n",
    "\n",
    "\n",
    "def plot_translations(result_dir):\n",
    "    num_imgs = 50\n",
    "    _celeba, _bitmoji = get_data(num_imgs)\n",
    "    direc = project_dir + 'gan/celeba_bitmoji/results/' + result_dir + '/'\n",
    "    best_fname = give_best_fname(direc)\n",
    "    best_mod = CBCycleWGAN.load_from_checkpoint(best_fname)\n",
    "    see_some_translations(best_mod, _celeba, _bitmoji, 'best')\n",
    "    mod = CBCycleWGAN.load_from_checkpoint(project_dir + 'gan/celeba_bitmoji/results/' + result_dir + '/last.ckpt')\n",
    "    see_some_translations(mod, _celeba, _bitmoji, 'last')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d909668",
   "metadata": {},
   "source": [
    "## SVHN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_side_by_side(title, reals, gens, gray, fname):\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(8, 8))\n",
    "    fig.subplots_adjust(wspace=0.01, hspace=0.01, left=0, bottom=0, right=1, top=0.95)\n",
    "    axes = axes.flat\n",
    "\n",
    "    for i in range(reals.shape[0]):\n",
    "        target_idx = 2 * i\n",
    "        ax = axes[target_idx]\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        if gray == 'real':\n",
    "            ax.imshow(reals[i], cmap='gray', vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(reals[i])\n",
    "\n",
    "        pred_idx = target_idx + 1\n",
    "        ax = axes[pred_idx]\n",
    "        ax.set_axis_off()\n",
    "        if gray == 'gen':\n",
    "            ax.imshow(gens[i], cmap='gray', vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(gens[i])\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.savefig(project_dir + f'gan/svhn_mnist/img_results/{fname}')\n",
    "\n",
    "\n",
    "def convert_to_image(ndarray):  # -1 to 1\n",
    "    ndarray = ndarray * 0.5 + 0.5  # 0 to 1\n",
    "    ndarray *= 255  # 0 to 255\n",
    "    ndarray = numpy.round(ndarray, decimals=0)  # rounded off\n",
    "    return ndarray.astype(int)\n",
    "\n",
    "\n",
    "def see_some_translations(model, svhn, mnist, model_type):\n",
    "    gen_mnist = model.genS2M(svhn).detach().numpy()\n",
    "    gen_svhn = model.genM2S(mnist).detach().numpy()\n",
    "\n",
    "    svhn = convert_to_image(numpy.transpose(svhn.numpy(), (0, 2, 3, 1)))\n",
    "    mnist = convert_to_image(numpy.transpose(mnist.numpy(), (0, 2, 3, 1)))\n",
    "    gen_mnist = convert_to_image(numpy.transpose(gen_mnist, (0, 2, 3, 1)))\n",
    "    gen_svhn = convert_to_image(numpy.transpose(gen_svhn, (0, 2, 3, 1)))\n",
    "\n",
    "    plot_side_by_side(f'SVHN to MNIST - NCritic = {model.ncritic}, NGen = {model.ngen}, Cycle Weight = {model.cycle_weight} - {model_type}',\n",
    "                      svhn, gen_mnist, 'gen',\n",
    "                      f'gan_trans_ncritic={model.ncritic}_ngen={model.ngen}_cycleweight={model.cycle_weight}_{model_type}_s2m')\n",
    "    plot_side_by_side(f'MNIST to SVHN - NCritic = {model.ncritic}, NGen = {model.ngen}, Cycle Weight = {model.cycle_weight} - {model_type}',\n",
    "                      mnist, gen_svhn, 'real',\n",
    "                      f'gan_trans_ncritic={model.ncritic}_ngen={model.ngen}_cycleweight={model.cycle_weight}_{model_type}_m2s')\n",
    "\n",
    "\n",
    "def get_data(num_images):\n",
    "    svhn_dataset = SVHN(svhn_data_dir, split='test',\n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                        ]))\n",
    "    svhn_dataloader = DataLoader(svhn_dataset, num_images, shuffle=True, num_workers=num_cpus,\n",
    "                                 collate_fn=custom_collate_fn)\n",
    "    mnist_dataset = MNIST(mnist_data_dir, train=False,\n",
    "                          transform=transforms.Compose([\n",
    "                              transforms.ToTensor(),  # Gives a scaled version i.e., 0 to 1\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                          ]))\n",
    "    mnist_dataloader = DataLoader(mnist_dataset, num_images, shuffle=True, num_workers=num_cpus,\n",
    "                                  collate_fn=custom_collate_fn)\n",
    "    svhn = next(iter(svhn_dataloader))\n",
    "    mnist = next(iter(mnist_dataloader))\n",
    "    return svhn[0], mnist[0]\n",
    "\n",
    "\n",
    "def give_best_fname(direc):\n",
    "    data = []\n",
    "    for fname in glob(direc + 'epoch*.ckpt'):\n",
    "        val_loss = float(fname.replace(direc, '').split('=')[2].replace('.ckpt', ''))\n",
    "        data.append({'fname': fname, 'val_loss': val_loss})\n",
    "    df = pandas.DataFrame(data)\n",
    "    min_idx = df.val_loss.idxmin()\n",
    "    best_fname = df.fname[min_idx]\n",
    "    return best_fname\n",
    "\n",
    "\n",
    "def plot_translations(result_dir):\n",
    "    num_imgs = 50\n",
    "    _svhn, _mnist = get_data(num_imgs)\n",
    "    direc = project_dir + 'gan/svhn_mnist/results/' + result_dir + '/'\n",
    "    best_fname = give_best_fname(direc)\n",
    "    best_mod = SMCycleWGAN.load_from_checkpoint(best_fname)\n",
    "    see_some_translations(best_mod, _svhn, _mnist, 'best')\n",
    "    mod = SMCycleWGAN.load_from_checkpoint(project_dir + 'gan/svhn_mnist/results/' + result_dir + '/last.ckpt')\n",
    "    see_some_translations(mod, _svhn, _mnist, 'last')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
